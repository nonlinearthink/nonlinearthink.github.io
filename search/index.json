[{"content":"每当我们的人生进入重大的转折点时，你就会发现，原本那些与你同行的人，要不瞬间离开不见踪影，要不渐行渐远慢慢淡忘，而新的人和关系又会逐渐团聚在你的周围。\n我曾经不甚理解，但在漫长的人生中最终悟道，希望把一些思考分享给比别人。\n人生岔路口 到哪个城市发展 地理的因素是影响人们交流的一个重要因素，假如你过去的同学并不和你在同一个城市，那么你们再产生交集的概率也会很低。\n大家从五湖四海到同一个城市读大学的这个四年才是意外，在自己的城市工作和生活才是常态。\n过去的同学注定是渐行渐远，不要尝试挽留，各自安好就行。\n追求幸福还是成功 幸福与成功不可兼得。 你渴望成功就要牺牲幸福的人生，你渴望幸福的人生就要放弃追求成功。\n因为幸福来源于你对现状的满足感，而追求成功来源于你想要改变现状。\n你的欲望如果不是无底洞，那么最终，你都会到达满足于现状的状态。每个人最终停下的位置不同，故而我们对成功的定义也并不相同。在你成功之后，仍要学会，如何获取幸福。\n不要评价别人的选择 就像我们有的人选择考公，而有的人选择创业。你不能因为自己要创业，就让别人放弃考公。\n基于幸福和成功的相对性，我们可知选择与选择之间并没有绝对的好坏。而如果你总是以自己的标准来评价别人，那么大概率你只会获得一个结论：我是对的，他是错的。\n人皆是知行合一的，你的行为背后一定有你的逻辑支撑，而你的标准又是构建于你的逻辑之上，所以，无论你如何比较，最终都会得到对方不如你的结论。\n没有人可以在你的标准中打败你。 如果有，出于维护自尊的需要，你会在不自觉的情况下更改你的标准。\n总而言之，不要去评价别人的人生选择，你要理解，每个人基于自己想要的东西而选择自己的路径。\n这也给了我们启示，要善于发现别人的优点，来弥补自己的不足，通过合作实现共赢，而不是用自己的标准去评价别人，得到别人不如你的结论。\n适应新常态，基于利益驱动的朋友 在过去上学的时候，我们交朋友基本上是情绪驱动的。也就是，与某个人相处让你感觉很舒服很自然。\n学生时代的我们，实际上并没有太多的利益相关的东西，故此仍然保持着一种比较纯粹和自然的交朋友方式。\n但当你步入社会，并期待完成某些事情，达成某些目的，获取某些“成功”之后，你交朋友的目的就不再是情绪驱动了。你交的朋友，是一个交易的对象，你们交换各自想要的东西，然后又各自前进，你们是利益驱动的关系。\n你可能会感觉不适应，感觉迷茫，感觉痛苦。但是，对于追求成功的人来说，孤独是一种常态，在你成功之前，没有人能理解你也是常态。\n","date":"2024-08-28T13:53:24+08:00","permalink":"https://nonlinearthink.github.io/p/%E5%88%B0%E4%BA%86%E5%88%86%E5%8F%89%E8%B7%AF%E5%8F%A3%E5%B0%B1%E8%AF%B4%E5%86%8D%E8%A7%81/","title":"到了分叉路口就说再见"},{"content":"为什么要创业？ 人类从奴隶制转向雇佣制，但是没有改变的是，大部分人依旧没有掌握生产资料。生产资料如此重要，因为掌握了它的人可以在不劳动的情况下，依旧产生收入。这就是真正的自由。\n当你在打工的时候，你默许了自己的劳动成果，被转交给老板，以换取一份微薄和稳定的收入，同时失去了一个可以为你持续赚钱的资产。\n故此，当你出现“35岁危机”的时候，其实这样的处境正是你自己的短视造成的，却丝毫不自知。\n即便你不创业，也应该获取一些高速成长的公司的股份，以实现个人资产的增值。\n赚钱的本质是为别人解决问题 你解决了 10 块的问题，就只能获得 10 块的奖励；解决了 1 万的问题，就能获得 1 万的奖励。客单价反映了你解决的这个问题对别人来说的价值。\n不要去相信坑蒙拐骗的赚钱方法，也许可以赚到钱，但是无法持久，无法持久的生意注定会而做得很累。\n创办一家公司并不轻松，因为你需要知道在这个社会中哪些问题还没有被解决，并且知道怎么去解决问题。\n验证可行性 对于创业项目来说，大体上存在两个方向，验证它们的可行性有着些许差异：\n模仿头部公司的产品和服务，压低价格，且做差异化竞争。\n这种在执行层面可能并不存在问题，你要考虑的是价格带来的一系列可行性问题，也就是在价格压低的情况下，核算完成这件事需要的成本，判断是否可以盈利。\n不过价格战是很幸苦的，做不长久，最终还是要回到”寻找客户的痛点，做差异化创新“的路上。\n做从来没有做过的产品和服务。\n这种就比较狂野了，你的验证成本会非常高，在没有融资的情况下完全做不了。\n首先是需求的可行性，你需要大量的调研和反馈，来理解是否有人愿意为此付费，其次，你可能需要应用非常前沿的技术，甚至得自己发明新的技术。\n不过我认为这样的公司在未来将会是主流，因为国内的经济经过这么多年的发展，各行各业基本上都是一片红海，在这样的环境下白手起家，开辟出一片蓝海可能是最佳方案。\n构建最小可用产品 当你理解了需要去解决的问题，并且有了一个大致的答案，并且基本验证了可行，就需要开始构建你的第一个产品或者服务。我们把它叫做最小可用产品(MVP)。\n它大概率不是完美的，甚至是一堆你自己都不忍直视的垃圾。但是正所谓这个世界就是一个巨大的草台班子，没有人能在没有任何经验的情况下把一件事情做到完美。\n我很喜欢程序员经常挂在嘴边的一句话：It Works.\n在最开始的几个订单中，你需要关注产品而不是急于赚钱。不妨多听听你客户的抱怨，在这个过程中，构建完整的产品并找到产品的最终定位。\n复制和裂变 当你发现了一群人都需要解决这个问题，就可以复制这个流程无数次。如果一个生意无法被复制无数次，那么它就不是一个好的生意。\n复制成本 复制并不是没有成本的。\n材料和设备成本 生产实物商品一定会存在材料和设备成本，你需要拥有一定的启动资金才可以负担。\n时间成本 假设现在你正在做为别人修理空调的服务，尽管它不再要求你拥有庞大的启动资金，但是这个服务需要花费时间才能完成。\n如果你花的都是自己的时间，那么赚钱的速度就会慢很多，因为你的时间是有限的资源。这个时候你就需要去购买别人的时间，并从中赚取利差。\n销售成本 如果你什么都不做，客户是很难找到你的。营销和销售是企业最重要的一环。\n但是销售的成本可能不一定是指找到客户的成本。\n你的客户（特别是大型企业）往往会存在拖欠账款、占用上下游现金流的问题，这是一种无息贷款，因为你缺乏议价权，所以只能接受。被拖欠账款的企业如果现金流断裂，即便账面上是盈利的也会破产。\n销售需要关注的不止是把产品”卖出去“，还有把钱“收回来”。\n利用互联网实现裂变 互联网为商业带来了巨大的变革。就像你一直在电脑前做的那样，CtrlC 然后 CtrlV。\n程序员只需要编写程序一次，却可以服务全世界范围内的人无数次。\n在过去，教育工作者习惯于线下当面的培训，故而很难突破个人时间的限制。但是现在，很多人开始在线上贩卖课程，只需要录制一次却可以复制无数次，知识变现已然成为了一个巨大的风口。\n自信地迈出你的步伐 自信虽然不是成功的充要条件，但却是成功的必要条件。 如果你自己都不相信一件事情可以被自己完成，那么它就一定完不成。\n这个世界从来没有真正为任何人设置任何的限制，每一个人都生来圆满而自由，而一切的阻碍和限制都来自我们自己。\n我们可能已经习惯了在能力边界内，过着舒适的生活，一旦离开那里，就会变得患得患失，变得不自信，做不好任何事情。\n尝试给自己设立一个难以完成的目标，并花费一生去追求它。你一无所有地来到这个世界上，一无所有地离开这个世界。赚钱了，亏钱了，到头来钱不过是一串数字，而在这个过程中不断突破自己的能力边界才是属于你真正的财富。\n","date":"2024-07-26T21:34:48+08:00","permalink":"https://nonlinearthink.github.io/p/%E7%9C%9F%E6%AD%A3%E8%B5%9A%E9%92%B1%E7%9A%84%E4%BA%8B%E6%83%85%E5%92%8C%E8%B5%9A%E9%92%B1%E6%97%A0%E5%85%B3/","title":"真正赚钱的事情和赚钱无关"},{"content":"课程的链接：PARALLEL COMPUTING(Standford CS149)\n本文是我个人的学习笔记，适合没那么多时间想要快速过一遍或者英文不好的同学阅读。\nWhy Parallelism? Why Efficiency? 为什么需要并行？ 在过去很长一段时间，处理器性能的提升得益于两方面：\n指令级并行（Instruction Level Parallelism）的发展\n处理器底层实际上有并行运行的机制，但因为对程序员是不可见的，所以一般人不知道。对于没有依赖关系的指令，现代的处理器会使用并行执行。类似如图所示：\n“没有依赖关系”是指，这条指令不需要等待其他指令执行完毕，才能执行。\n超标量处理器（Superscalar Processor）是指能找到可并行执行的指令，并行运行的处理器，其与普通处理器的区别如图所示：\n处理器频率的提升\n著名的摩尔定律：处理器的性能每 18 个月就会翻一番。\n得益于这些原因，在过去很长一段时间内，软件开发者不需要修改任何程序，仅仅更换硬件就能让程序越来越快。\n不幸的是 ILP 的研究已经到顶，CPU 的频率由于要考虑功耗无法再继续提升，如今，处理器的性能提升主要来自于在单位面积中堆叠更多的晶体管：\n与此同时，多核处理器如今已经成为了主流，程序员必须要编写并行的程序才能利用多核处理器的优势。No more free lunch for software developers!\n为什么需要高效？ 仅仅编写并行的程序是不行的，程序也必须是高效的。高效也是讨论并行编程的关键主题。\n而高效的并行编程往往来自于高效的数据访问。\n延迟和停顿 使用 R0 \u0026lt;- mem[R2] 指令访问数据，它发起一个请求，把内存中地址 R2 位置的数据传送给 R0 寄存器。在这个过程中，因为需要等待数据传输完毕，会造成一个延迟（Memory Access Latency）:\n处理器无法运行下一条指令，因为需要等待上一条指令完成。这种现象叫做 停顿(Stall)。\n带宽 时钟（Clock） 是指处理器执行一次运算需要的时间。如图所示：\nMath instruction 的运行时长是一次时钟 Load instruction 的运行时长是不固定的，取决于内存带宽（Memory Bandwidth） 如果一些 Math instruction 需要依赖于 Load instruction 的结果，就只能等待，于是就造成一次停顿。\n大部分时候，处理器都在等待数据被加载，内存带宽几乎决定了处理器的运行速度。相比于从内存中加载数据，The math is \u0026ldquo;free\u0026rdquo;.\n所以，高性能的并行程序会尽可能减少从内存中请求数据的次数，并且更倾向于重新计算而不是存储/加载值，这一点可以从 GPU 的 Shader 编程中看出来。\n缓存 使用缓存(Cache)可以减少停顿的长度。什么是缓存？\n缓存是硬件实现，软件程序不需要关注。\n缓存只是管理一份数据的拷贝。\n在缓存中读取/写入的速度要比内存快得多。\n缓存以“缓存行(Cache Lines)” 的形式读取/写入数据。\n如图所示，每行由一条指向内存的地址和一定长度的数据组成。每次读取/写入以一行为单位。\n缓存分为很多级别，级别越高，访问速度越快，但容量越小。各个级别的缓存延迟对比图：\n为了尽可能使用速度快的缓存，需要缓存调度策略。比如：Least Recently Used(LRU)。\n在一些现代处理器中，存在预测在未来可能会被访问的数据，并提前放入 Cache 中的逻辑。\n早期的多核处理器 A Modern Multi-Core Processor SIMD 什么是 SIMD SIMD(Single Instruction, Multiple Data) 的核心理念是在多个 ALU 中分摊管理指令流的成本/复杂性，把相同的指令广播给所有的 ALU 并行运行。即一条指令处理多个数据，常用于向量或者矩阵的计算。一个支持 SIMD 的处理器的例子：\n在汇编代码中，有专用的指令：\n这段代码使用一个 256(8 * 32) 位的寄存器存储 8 个数字，并行计算它们并输出结果。\nSIMD 和 ILP 并不同，SIMD 是使用一条指令计算多个数据，而 ILP 则是基于指令的依赖关系去让一些指令可以并行执行。它们可以同时存在。\nSIMD 的执行分歧 如果遇到需要条件执行的程序，使用 SIMD 会导致执行分歧：\n这意味着在一段时间内部分 ALU 是不工作的，导致了性能的浪费。在极端的情况下，可能会导致 CPU 仅使用 $\\frac{1}{N}$ 的性能（仅有一个 ALU 工作）。\n如何使用 SIMD Explicit SIMD，程序员使用显式调用封装了 SIMD 的库 Implicit SIMD，程序员仅编写高级语言的代码，由特殊的编译器自动生成 SIMD 的汇编指令 线程 线程（Thread），是指在一个处理器核心（Core）中，有多个执行上下文，线程并不能真正并行运行，它只是从一个执行上下文切换到另外一个执行上下文，轮流执行。在其他线程执行的时候，执行完的线程也不会结束，会有很长的停顿。\n使用线程还需要付出代价：因为存储执行上下文的物理单元也是有限的，更多的线程意味着程序的可用执行上下文会更小。\n总结 在现代处理器中，实现并行的方法有：\nMuti-Core ILP SIMD Thread 外加实现高效数据读取/写入的 Cache，它们一起构成了这张现代处理器的并行架构图（同时适用于 CPU 和 GPU）：\n","date":"2024-03-06T12:23:24+08:00","permalink":"https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/","title":"PARALLEL COMPUTING 课程笔记（一）"},{"content":"软件由需求驱动，而需求会不断变化，随着时间的变化，系统的熵必然会不断增加，软件开发就是控制系统熵减的一个过程。那么，如何编写一个可维护、可理解和可扩展的软件？\n本文旨在介绍一个有着 20 年历史的面向对象 SOLID 设计原则，可能会对你有所帮助。\nSOLID 简介 SOLID 是面向对象编程领域的五个设计原则，由它们的首字母缩写而来：\nSingle Responsibility Principle（单一功能原则） Open/Closed Principle（开闭原则） Liskov Substitution Principle（里氏替换原则） Interface Segregation Principle（接口隔离原则） Dependency Inversion Principle（依赖反转原则） 你大概率已经听过这些名词，假如它们出现在一本介绍编程的书里面，你大概率会忽略它们，因为它们看起来和你要做的编程工作没有关系。\n假如你是一个有了一定经验的程序员，看到这些名词，并理解它们，你可能会非常兴奋。因为这正是你在寻找的东西。\n通过例子学习 SOLID Single Responsibility Principle 即单一功能原则，从字面意思上来讲，就是一个类只能有一个功能。但是假如真的这么做，无疑是过度设计了，所以我更愿意这样子理解：假如你有一个类，经常修改它并且总是出于不同的原因，那么你应该尝试把它拆分成不同的类。\n这样做的好处是可以设计充分的单元测试，错误也更容易定位。\n例如，有一个 Text 类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Text { public: void Append(const std::string \u0026amp;text) { text_.append(text); } void DeltetLastCharacter() { text_.pop_back(); } void DeleteSubString(const std::string \u0026amp;substring) { text_.erase(text_.find(substring), substring.length()); } void Print() { std::cout \u0026lt;\u0026lt; text_; } void PrintLastCharacter() { std::cout \u0026lt;\u0026lt; text_.back(); } void PrintLength() { std::cout \u0026lt;\u0026lt; text_.length(); } private: std::string text_; }; 它有 Append、Delete、Print 方法。根据 SRP 原则，我们可以认为 Append、Delete 都属于操作文本，而 Print 则属于输出文本到另外一个地方，借此可以把 Print 相关的函数放到一个新的 TextPrinter 类里面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Text { public: void Append(const std::string \u0026amp;text) { text_.append(text); } void DeltetLastCharacter() { text_.pop_back(); } void DeleteSubString(const std::string \u0026amp;substring) { text_.erase(text_.find(substring), substring.length()); } std::string \u0026amp;GetText() { return text_; } private: std::string text_; }; class TextPrinter { public: void Print() { std::cout \u0026lt;\u0026lt; text_.GetText(); } void PrintLastCharacter() { std::cout \u0026lt;\u0026lt; text_.GetText().back(); } void PrintLength() { std::cout \u0026lt;\u0026lt; text_.GetText().length(); } private: Text text_; }; 任何开发过软件的人都明白，这不是一条容易遵守的规则，因为比较极端的情况下，似乎我们得要为每一个功能都设计一个类，这是不现实的。\n知道哪些类可以拆分很重要，这需要你动用领域驱动设计（DDD）的思想，充分了解具体的业务模型，以此来决定类的粒度。如果实在是觉得纠结，这里还有一些数学方法来衡量类的内聚性：Cohesion metrics，不再展开。\nOpen/Closed Principle 即开闭原则，开闭原则的全称是 Open for Extension, Closed for Modification。它的主要指导思想是一个类被设计完之后，就不应该再被修改了，而是基于抽象去做扩展。这听起来简直匪夷所思，天方夜谭，白日做梦。让我们看一个 Calculator 类的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 enum class CalculatorOperation { ADD, SUB }; class Calculator { public: Calculator(float left, float right) : left_(left), right_(right) {} void Calculate(CalculatorOperation operation) { switch (operation) { case CalculatorOperation::ADD: result_ = left_ + result_; break; case CalculatorOperation::SUB: result_ = left_ - result_; break; default: break; } } private: float left_; float right_; float result_; }; 这看上去没什么问题，但是假如之后有新的操作，比如乘法，除法，或者平方根，我们该如何处理？\n你可能会说添加一个新的 case，但是这就违背了开闭原则，它修改了已经存在的类。我们看一个更符合开闭原则的实现方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class CalculatorOperation { public: virtual float Operation(float left, float right) = 0; }; class Addition : public CalculatorOperation { public: float Operation(float left, float right) override { return left + right; } }; class Subtraction : public CalculatorOperation { public: float Operation(float left, float right) override { return left - right; } }; class Calculator { public: Calculator(float left, float right) : left_(left), right_(right) {} void Calculate(CalculatorOperation operation) { result_ = operation.Operation(left_, right_); } private: float left_; float right_; float result_; }; 我们巧妙地把所有操作抽象成一个接口，然后让 Calculator 类依赖这个接口，这样就避免了修改 Calculator 类。\nLiskov Substitution Principle 即里氏替换原则，它的规则很简单：子类型应该能替换父类型出现的位置且无需改动任何代码。\n虽然看起来很简单，但是实际做起来非常有讲究，我们可以参考 Program Development in Java: Abstraction, Specification, and Object-Oriented Design，里面提出了一些建设性的建议。\n子类重写父类方法，参数类型的范围可以扩大或相同。 子类重写父类方法，返回类型的范围只能缩小或者相同。 子类重写父类方法，不能抛出父类没有抛出的异常。 子类重写父类方法，方法运行前的条件要一致。 子类重写父类方法，方法运行后的条件要一致。 子类属性要满足父类属性的约束。 子类不能允许修改父类不曾修改的属性。 这是一个遵守 LSP 的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Rectangle { public: Rectangle(int width, int height) : width_(width), height_(height) {} [[nodiscard]] int GetWidth() const { return width_; } [[nodiscard]] int GetHeight() const { return height_; } private: int width_, height_; }; class Square : public Rectangle { public: explicit Square(int size) : Rectangle(size, size) {} }; Square 的宽和高是一样的，它比 Rectangle 多一个约束条件，所以 Square 继承 Rectangle 是可行的，但是反过来就不对。\nInterface Segregation Principle 即接口隔离原则，这个比较容易理解，即尽可能把接口设计得足够小。\n假如我们有一个 Human 类：\n1 2 3 4 5 6 class Human { public: virtual void Eat() = 0; virtual void Run() = 0; virtual void Speak() = 0; }; 我们很容易想到，Eat、Run 不是 Human 特有的行为，Speak 看上去像是 Human 特有的行为，但是我们也许 Alien 也有这个行为。\n所以我们应该拆分成更细粒度的接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Eatable { public: virtual void Eat() = 0; }; class Runable { public: virtual void Run() = 0; }; class Speakable { public: virtual void Speak() = 0; }; Dependency Inversion Principle 即依赖反转原则，在我们设计软件的时候，很容易基于想到，上层模块应该依赖底层模块，但是依赖反转原则想要告诉你，上层模块不应该依赖于底层模块，而是依赖于抽象。这种情况在后端编程的时候非常常见：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class ILoginService { public: virtual bool Login() = 0; }; class UserService : public ILoginService { public: bool Login() {} }; class AdminService : public ILoginService { public: bool Login() {} }; class FileController { public: void Upload() { bool access = loginService-\u0026gt;Login(); if (access) { // Do Upload } } private: ILoginService *loginService; }; 在这里，FileController 类依赖了 ILoginService 接口，而不是直接使用 UserService 类，这样就避免了后续添加 AdminService 类后，FileController 类需要兼容 AdminService 类的逻辑。\n总结 SOLID 是面向对象程序设计领域的五个原则的缩写，分别是：\n单一功能原则，一个类只应该负责一个单一的功能 开闭原则，需求变动的时候，不应该修改类，而是扩展类 里氏替换原则，派生类要能完全替换基类出现的位置，且代码行为要保持一致 接口隔离原则，不同的领域要分成不同的接口，不能混合在一起 依赖反转原则，高层模块不应该依赖于底层模块，而是依赖于抽象接口 尝试在日常的代码编写中思考和应用这些原则。\n参考资料 A Solid Guide to SOLID Principles Single Responsibility Principle in Java Open/Closed Principle in Java Liskov Substitution Principle in Java ","date":"2024-02-27T21:56:50+08:00","permalink":"https://nonlinearthink.github.io/p/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-solid-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","title":"面向对象 SOLID 设计原则"},{"content":"解析 Supermap Rest 根目录 从 Supermap Rest 服务的根目录出发，第一步是请求 CatalogList。返回的结构大致是这样子的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [ { \u0026#34;resourceConfigID\u0026#34;: \u0026#34;maps\u0026#34;, \u0026#34;supportedMediaTypes\u0026#34;: [ \u0026#34;application/xml\u0026#34;, \u0026#34;text/xml\u0026#34;, \u0026#34;application/json\u0026#34;, \u0026#34;application/fastjson\u0026#34;, \u0026#34;application/rjson\u0026#34;, \u0026#34;text/html\u0026#34;, ... ], \u0026#34;path\u0026#34;: \u0026#34;http://192.168.31.4:8090/iserver/services/map-China/rest/maps\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;maps\u0026#34;, \u0026#34;resourceType\u0026#34;: \u0026#34;CatalogList\u0026#34; }, ... ] 我们需要里面的 \u0026quot;path\u0026quot;，去请求一个 CatalogList，可以取出对应的 \u0026quot;name\u0026quot;，让用户自己去选择请求哪个 CatalogList。\n一个简单的 SupermapRestClient 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 export class SupermapRestClient { private _url: string; constructor(url: string) { this._url = url; } async doRequest() { const resource = new Cesium.Resource(this._url + \u0026#34;.json\u0026#34;); const json = await resource.fetchJson(); const resourceList: { name: string; client: SupermapCatalogListClient }[] = []; for (const item of json) { if (item.resourceType === \u0026#34;CatalogList\u0026#34;) { resourceList.push({ name: item.name, client: new SupermapCatalogListClient(item.path) }); } } return resourceList; } } 其中的 SupermapCatalogListClient 在下一小节实现。\n获取 CatalogList 现在假如用户已经选择需要请求的 CatalogList，再来看以一下 CatalogList 的结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [ { \u0026#34;resourceConfigID\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;supportedMediaTypes\u0026#34;: [ \u0026#34;application/xml\u0026#34;, \u0026#34;text/xml\u0026#34;, \u0026#34;application/json\u0026#34;, \u0026#34;application/fastjson\u0026#34;, \u0026#34;application/rjson\u0026#34;, \u0026#34;text/html\u0026#34;, ... ], \u0026#34;path\u0026#34;: \u0026#34;http://192.168.31.4:8090/iserver/services/map-China/rest/maps/China\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;China\u0026#34;, \u0026#34;resourceType\u0026#34;: \u0026#34;StaticResource\u0026#34; }, ... ] 同理，取出 \u0026quot;path\u0026quot; 和 \u0026quot;name\u0026quot;，一个简单的 SupermapCatalogListClient 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 export class SupermapCatalogListClient { private _url: string; constructor(url: string) { this._url = url; } async doRequest() { const resource = new Cesium.Resource(this._url + \u0026#34;.json\u0026#34;); const json = await resource.fetchJson(); const resourceList: { name: string; client: SupermapRestStaticResourceClient }[] = []; for (const item of json) { if (item.resourceType === \u0026#34;StaticResource\u0026#34;) { resourceList.push({ name: item.name, client: new SupermapRestStaticResourceClient(item.path) }); } } return resourceList; } } 其中的 SupermapRestStaticResourceClient 在下一小节实现。\n获取 StaticResource 获取 Capabilities 在很多地图协议中，地图的 metadata 一般也叫做 Capabilities， StaticResource 请求的就是地图的 metadata，所以一个简单的 SupermapRestStaticResourceClient 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 export class SupermapRestStaticResourceClient { private _url: string; constructor(url: string) { this._url = url; } async getCapabilities() { const jsonResource = new Cesium.Resource(this._url + \u0026#34;.json\u0026#34;); return await jsonResource.fetchJson(); } } 这个返回的 json 里面有很多信息，但是没有我们最需要的地图瓦片地址，先忽略它，之后再来看。\n获取地图瓦片 打开 iServer 的 Rest 服务地图列表界面，可以看到有一些可以预览效果的链接。\n通过查看网络请求，可以找到地图瓦片请求，显示最后请求的是一个 tileImage.png 的图片：\n以此，可以为 SupermapRestStaticResourceClient 添加一个新的方法来构造这个请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 export class SupermapRestStaticResourceClient { ... getTileImageResource(tilingScheme: Cesium.TilingScheme) { let originX: number; let originY: number; if (tilingScheme instanceof Cesium.WebMercatorTilingScheme) { originX = -20037508.342787; originY = 20037508.342787; } else { originX = -180; originY = 90; } const tileImageResource = new Cesium.Resource(this._url + \u0026#34;/tileImage.png\u0026#34;); tileImageResource.appendQueryParameters({ transparent: true, cacheEnabled: true, width: 256, height: 256, redirect: false, overlapDisplayed: false, origin: `{x:${originX},y:${originY}}`, x: \u0026#34;{x}\u0026#34;, y: \u0026#34;{y}\u0026#34;, scale: \u0026#34;{scale}\u0026#34; }); return tileImageResource; } } 其中，origin 需要根据不同的投影坐标系或者地理坐标系进行修改，x, y, scale 这三个参数交给 Cesium 去填写。\nx 和 y 很好理解，就是水平和垂直方向上的瓦片坐标，但是 scale 是什么。\n计算 scale 在 Supermap 的文档中，可以找到相关的描述：scale\n$$ scale = \\frac{1}{Resolution \\frac{PPI}{0.0254}} $$\nResolution 代表每一个像素有多少实际距离 PPI 代表了每一英尺有多少个像素，这个数值一般为 96 0.0254 是英尺和米的转换比例 以 WebMercator 为例，它的第 0 级瓦片整张地图实际大小为 40075016.68×40075016.68 米左右，假如向 Supermap 发起一个 256×256 像素大小的图片请求，那么：\n$$ \\begin{aligned} \\cr Resolution \u0026amp;= \\frac{40075016.68}{256} = 156543.03\\cr scale \u0026amp;= \\frac{1}{156543.03 \\frac{96}{0.0254}} = 1.6901635718379278e-9 \\end{aligned} $$\n以此类推，我们可以计算出 WGS84 和 WebMercator 各个级别下的 scale 值，并用一个数组来表示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 const WGS84Scales = [ 3.38032714321e-9, 6.76065428641e-9, 1.352130857282e-8, 2.704261714564e-8, 5.408523429128e-8, 1.0817046858257e-7, 2.1634093716514e-7, 4.3268187433028e-7, 8.6536374866056e-7, 1.73072749732112e-6, 3.46145499464224e-6, 6.92290998928448e-6, 1.3845819978568952e-5, 2.7691639957137904e-5, 5.538327991427581e-5, 1.1076655982855162e-4, 2.2153311965710323e-4, 4.4306623931420646e-4, 8.861324786284129e-4, 0.0017722649572568258, 0.0035445299145136517, 0.007089059829027303 ]; const WebmercatorScales = [ 1.6901635716e-9, 3.38032714321e-9, 6.76065428641e-9, 1.352130857282e-8, 2.704261714564e-8, 5.408523429128e-8, 1.0817046858257e-7, 2.1634093716514e-7, 4.3268187433028e-7, 8.6536374866056e-7, 1.73072749732112e-6, 3.46145499464224e-6, 6.92290998928448e-6, 1.3845819978568952e-5, 2.7691639957137904e-5, 5.538327991427581e-5, 1.1076655982855162e-4, 2.2153311965710323e-4, 4.4306623931420646e-4, 8.861324786284129e-4, 0.0017722649572568258, 0.0035445299145136517, 0.007089059829027303 ]; 获取 Rectangle 和 TilingScheme Rectangle 就是 Cesium 里面的经纬度范围，TilingScheme 就是 Cesium 里面的投影坐标系和地理坐标系。\n这些信息被记录在一开始我们请求的 Capabilities 里面。\n为 SupermapRestStaticResourceClient 添加一个新的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 export class SupermapRestStaticResourceClient { ... getTilingSchemeFromCapabilities(capabilities: any) { let tilingScheme: Cesium.TilingScheme; if (capabilities.prjCoordSys.epsgCode === 4326) { const rectangle = new Cesium.Rectangle( capabilities.bounds.left, capabilities.bounds.bottom, capabilities.bounds.right, capabilities.bounds.top ); tilingScheme = new Cesium.GeographicTilingScheme({ numberOfLevelZeroTilesX: 2, numberOfLevelZeroTilesY: 1, rectangle }); } else if (capabilities.prjCoordSys.epsgCode === 3857) { const southwest = new Cesium.Cartesian2(capabilities.bounds.left, capabilities.bounds.bottom); const northeast = new Cesium.Cartesian2(capabilities.bounds.right, capabilities.bounds.top); tilingScheme = new Cesium.WebMercatorTilingScheme({ numberOfLevelZeroTilesX: 1, numberOfLevelZeroTilesY: 1, rectangleSouthwestInMeters: southwest, rectangleNortheastInMeters: northeast }); } else { throw new Error(`espsgCode ${capabilities.prjCoordSys.epsgCode} is not supported.`); } return tilingScheme; } } 构造 SupermapRestImageryProvider 最后使用 SupermapRestStaticResourceClient 去构造一个 SupermapRestImageryProvider，它继承自 Cesium.UrlTemplateImageryProvider：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 export class SupermapRestImageryProvider extends Cesium.UrlTemplateImageryProvider { private constructor(options: Cesium.UrlTemplateImageryProvider.ConstructorOptions) { super(options); } static async fromSupermapRestStaticResourceClient(client: SupermapRestStaticResourceClient) { const capabilities = await client.getCapabilities(); const tilingScheme = client.getTilingSchemeFromCapabilities(capabilities); const tileImageResource = client.getTileImageResource(tilingScheme); return new SupermapRestImageryProvider({ url: tileImageResource, tilingScheme, customTags: { scale: function (_imageryProvider: Cesium.UrlTemplateImageryProvider, _x: number, _y: number, level: number) { if (tilingScheme instanceof Cesium.WebMercatorTilingScheme) { return WebmercatorScales[level]; } else { return WGS84Scales[level]; } } } }); } } 其中，使用了 customTags 功能，因为 scale 不是 Cesium.UrlTemplateImageryProvider 默认有的参数，需要我们自定义一个函数返回在不同 level 下的 scale 值。\n代码调用流程 最后，演示如何去使用上面编写的方法。\n请求 CatalogList 1 2 3 4 5 6 7 const url = \u0026#34;你的 Supermap Rest 地址\u0026#34;; // 创建 SupermapRestClient const client = new SupermapRestClient(url); // 请求 CatalogList。 const catalogList = await client.doRequest(); 等待用户选择哪一个 CatalogList。\n请求 StaticResource 1 2 3 4 5 6 7 8 // 假设用户选择了第一个 const selectId = 0; // 获取用户选择的 CatalogListClient const catalogListClient: SupermapCatalogListClient = catalogList[selectId].client; // 请求 StaticResource const staticResourceList = await catalogListClient.doRequest(); 等待用户选择哪一个 StaticResource。\n添加 ImageryProvider 1 2 3 4 5 6 7 8 9 10 11 // 假设用户选择了第一个 const selectId = 0; // 获取用户选择的 StaticResourceClient const staticResourceClient: SupermapRestStaticResourceClient = staticResourceList[selectId].client; // 创建 ImageryProvider const provider = await SupermapRestImageryProvider.fromSupermapRestStaticResourceClient(staticResourceClient); // 添加 ImageryProvider viewer.imageryLayers.addImageryProvider(provider); 完整代码\u0026amp;效果图 完整代码：cesium-supermap-rest-imagery-provider\n参考资料 SuperMap iClient3D for WebGL SuperMapImageryProvider自定义实现 ","date":"2024-01-09T19:08:00+08:00","image":"https://nonlinearthink.github.io/p/cesiumjs-%E5%8A%A0%E8%BD%BD-supermap-rest-%E6%9C%8D%E5%8A%A1/cesium_hu15673621494704698851.jpg","permalink":"https://nonlinearthink.github.io/p/cesiumjs-%E5%8A%A0%E8%BD%BD-supermap-rest-%E6%9C%8D%E5%8A%A1/","title":"CesiumJS 加载 Supermap Rest 服务"},{"content":"求解绘制三角形问题 绘制三角形就是遍历每一个像素，然后，判断这个像素是否在三角形内部。\n但是万一，三角形很小，而屏幕很大，遍历每一个像素显然是非常低效的，在正式遍历前可以求出 Bounding Rect 来缩小范围：\n1 2 3 4 5 6 7 // Bounding Rect Vector2i min(0, 0); Vector2i max(width - 1, height - 1); min.x = std::max(min.x, std::min(p0.x, std::min(p1.x, p2.x))); min.y = std::max(min.y, std::min(p0.y, std::min(p1.y, p2.y))); max.x = std::min(max.x, std::max(p0.x, std::max(p1.x, p2.x))); max.y = std::min(max.y, std::max(p0.y, std::max(p1.y, p2.y))); 判断一个点是否在三角形内部，有很多方法，这里主要介绍重心坐标，因为这是图形学非常重要的一个知识点，而且也能非常好地解决这个问题。\n重心坐标（Barycentric Coordinate）的定义 假设平面上存在三角形的三个点 $a, b, c$，则平面上任意的点 $p$ 都可使用三角形的三个顶点表示：\n$$ \\begin{aligned} p \u0026amp;= a+\\beta(b-a)+\\gamma(c-a)\\cr p \u0026amp;= (1-\\beta-\\gamma)a+\\beta b+\\gamma c \\end{aligned} $$\n令：\n$$ \\begin{aligned} \\alpha \u0026amp;= 1-\\beta-\\gamma \\end{aligned} $$\n当 $\\alpha$、$\\beta$、$\\gamma$ 均大于 0 小于 1 时，$p$ 位于三角形内部 当 $\\alpha$、$\\beta$、$\\gamma$ 中有一个分量等于 0 时，$p$ 在三角形边上 当 $\\alpha$、$\\beta$、$\\gamma$ 中有两个变量等于 0 时，$p$ 在某个顶点上 以坐标形式表示：\n$$ p = (\\alpha, \\beta, \\gamma) $$\n重心坐标的计算 面积法 $$ \\begin{aligned} \\alpha = \\frac{A_a}{A_a+A_b+A_c} \\cr \\beta = \\frac{A_b}{A_a+A_b+A_c} \\cr \\gamma = \\frac{A_c}{A_a+A_b+A_c} \\end{aligned} $$\n求面积可以使用叉乘：\n$$ \\alpha = \\frac{A_a}{A} = \\frac{\\vert (c-b) \\times (c-p)\\vert}{\\vert (a-b) \\times (a-c)\\vert} $$\n但是求出来的 $\\alpha$ 失去了方向性。我们可以通过点乘一个法线来解决这个问题：\n$$ \\alpha = \\frac{((c-b) \\times (p-b))\\cdot n}{((b-a) \\times (c-a))\\cdot n} $$\n这个等式之所以成立的关键是两个向量 $a$、$b$ 的点乘表达式为： $$a\\cdot b = \\vert a\\vert\\vert b\\vert\\cos\\theta$$ 当它们相互垂直的时候，$\\cos\\theta = 1$，那么上面的表示式实际上可以被表达为： $$ \\alpha = \\frac{\\vert(c-b) \\times (p-b)\\vert \\vert n\\vert}{\\vert(b-a) \\times (c-a)\\vert \\vert n\\vert} = \\frac{\\vert(c-b) \\times (p-b)\\vert}{\\vert(b-a) \\times (c-a)\\vert} $$ 这个结果和之前的推导一样。\n同时我们从叉乘的定义中得到 $n = ab \\times ac$。\n最终，我们得到了最终结果：\n$$ \\begin{aligned} \\alpha \u0026amp;= \\frac{n_a \\cdot n}{n\\cdot n}\\cr \\beta \u0026amp;= \\frac{n_b \\cdot n}{n\\cdot n}\\cr \\gamma \u0026amp;= \\frac{n_c \\cdot n}{n\\cdot n} \\end{aligned} $$\n其中：\n$$ \\begin{aligned} n_a \u0026amp;= (c-b) \\times (p-b)\\cr n_b \u0026amp;= (a-c) \\times (p-c)\\cr n_c \u0026amp;= (b-a) \\times (p-a) \\end{aligned} $$\n代数法 把上一小节的公式，写成这样的形式：\n$$ \\beta(b-a)+\\gamma(c-a)+(a-p)= 0 $$\n分别带入 x 和 y，得到两个方程，求两个未知数：\n$$ \\begin{aligned} (x_b - x_a)\\beta+(x_c - x_a)\\gamma+(x_a - x_p) \u0026amp;= 0\\cr (y_b - y_a)\\beta+(y_c - y_a)\\gamma+(y_a - y_p) \u0026amp;= 0 \\end{aligned} $$\n最终的结果:\n$$ \\begin{aligned} \\gamma \u0026amp;= \\frac{(y_a-y_b)x_p+(x_b-x_a)y_p+x_a y_b-x_b x_a}{(y_a-y_b)x_c+(x_a-x_b)y_c+x_a y_b-x_b x_a}\\cr \\beta \u0026amp;= \\frac{(y_a-y_c)x_p+(x_c-x_a)y_p+x_a y_c-x_c x_a}{(y_a-y_c)x_b+(x_c-x_a)y_b+x_a y_c-x_c x_a}\\cr \\alpha \u0026amp;= 1-\\gamma-\\beta \\end{aligned} $$\n上面是标准的求法，还有一种捷径。\n把上面两个方程变成矩阵形式：\n$$ \\begin{aligned} \\begin{bmatrix} x_b - x_a \u0026amp; x_c - x_a \u0026amp; x_a - x_p \\cr \\end{bmatrix} \\begin{bmatrix} \\beta \\cr \\gamma \\cr 1 \\end{bmatrix} \u0026amp;= 0\\cr \\begin{bmatrix} y_b - y_a \u0026amp; y_c - y_a \u0026amp; y_a - y_p\\cr \\end{bmatrix} \\begin{bmatrix} \\beta \\cr \\gamma \\cr 1 \\end{bmatrix} \u0026amp;= 0 \\end{aligned} $$\n说明向量 $\\begin{bmatrix}x_b - x_a \u0026amp; x_c - x_a \u0026amp; x_a - x_p \\end{bmatrix}$ 垂直于向量 $\\begin{bmatrix}\\beta \u0026amp;\\gamma \u0026amp; 1\\end{bmatrix}$，向量 $\\begin{bmatrix}y_b - y_a \u0026amp; y_c - y_a \u0026amp; y_a - y_p \\end{bmatrix}$ 垂直于向量 $\\begin{bmatrix}\\beta \u0026amp;\\gamma \u0026amp; 1\\end{bmatrix}$。\n得到：\n$$ \\begin{bmatrix} x_b - x_a \\cr x_c - x_a \\cr x_a - x_p \\end{bmatrix}\\times \\begin{bmatrix} y_b - y_a \\cr y_c - y_a \\cr y_a - y_p \\end{bmatrix}= \\begin{bmatrix} k\\beta \\cr k\\gamma \\cr k \\end{bmatrix} $$\n这是最快的重心计算法，它只使用了一个叉乘就解决了问题。\n重心坐标代码实现 根据上面推导的公式，最终，代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 for (int y = min.y; y \u0026lt;= max.y; y++) { for (int x = min.x; x \u0026lt;= max.x; x++) { Vector3i vx(p1.x - p0.x, p2.x - p0.x, p0.x - x); Vector3i vy(p1.y - p0.y, p2.y - p0.y, p0.y - y); Vector3i u = vx.Cross(vy); if (std::abs(u.z) \u0026lt; 1) { continue; } Vector3f barycentric(1.f - (u.x + u.y) / (float)u.z, u.x / (float)u.z, u.y / (float)u.z); if (barycentric.x \u0026gt; 0 \u0026amp;\u0026amp; barycentric.x \u0026lt; 1 \u0026amp;\u0026amp; barycentric.y \u0026gt; 0 \u0026amp;\u0026amp; barycentric.y \u0026lt; 1 \u0026amp;\u0026amp; barycentric.z \u0026gt; 0 \u0026amp;\u0026amp; barycentric.z \u0026lt; 1) { PutPixel(Vector2i(x, y), color); } } } 参考资料 Fundamentals of Computer Graphics 三角形重心坐标 ","date":"2023-12-12T16:42:50+08:00","permalink":"https://nonlinearthink.github.io/p/%E7%BC%96%E5%86%99%E5%85%89%E6%A0%85%E5%8C%96%E6%B8%B2%E6%9F%93%E5%99%A8%E5%9B%9B%E7%BB%98%E5%88%B6%E4%B8%89%E8%A7%92%E5%BD%A2/","title":"编写光栅化渲染器（四）绘制三角形"},{"content":"DDA Line DDA(Digital Differential Analyzer) 正如其名，就是最直观的直线画法，原始的算法的描述如下：\n假设存在屏幕空间上的两个点 $(x1, y1)$ 和 $(x2, y2)$\n计算 $dx=x2-x1$，$dy=y2-y1$。 计算斜率 $k=\\frac{dy}{dx}$。 x 从 x1 出发，每次向 x2 移动一个单位，计算 $y=y1+k(x–x1)$。 1 2 3 4 5 6 7 8 9 10 11 12 void DDA(int x0, int y0, int x1, int y1) { // 计算 dx \u0026amp; dy \u0026amp; k int dx = x1 - x0; int dy = y1 - y0; float k = dy / dx; // 循环绘制每一个像素 for (int x = x1; x \u0026lt;= x2; x++) { putpixel(x, round(y1 + k * (x - x1)), RED); } } 原始算法看起来很可靠，但是仍然有一些可以优化的地方，因为直线是线性且均匀的，所以假如提前计算好了每一次循环的增量，就可以避免 y1 + k * (x - x1) 中的浮点数乘法。\n优化过后的 DDA 算法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 void DDA(int x0, int y0, int x1, int y1) { // 计算 dx \u0026amp; dy int dx = x1 - x0; int dy = y1 - y0; // 计算需要计算多少步像素 int steps = abs(dx) \u0026gt; abs(dy) ? abs(dx) : abs(dy); // 计算 x \u0026amp; y 每一步的增量 float xinc = dx / (float)steps; float yinc = dy / (float)steps; // 循环绘制每一个像素 float x = x0; float y = y0; for (int i = 0; i \u0026lt;= steps; i++) { putpixel(round(x), round(y), RED); x += xinc; y += yinc; } } Bresenham\u0026rsquo;s Line 从上面 DDA 的优化案例可以看出，避免浮点数操作就是优化画线算法的关键。\nBresenham's Line 相比 DDA 不仅有更少的浮点数运算，而且没有浮点数和整数的类型转换。\n算法的核心思想如下：\n在 $(x_k, y_k)$ 的位置时候，可能走向 $(x_k+1, y_k)$ 也可能走向 $(x_k+1, y_k+1)$，显然，斜线的交点更加靠近谁，就往哪个方向走。\n斜率:\n$$ k = \\frac{\\Delta y}{\\Delta x} $$\n对于每一次循环，执行：\n$$ x_{i+1} = x_i + 1\\ e_{i+1} = e_i + k\\ $$\n同时，始终保证 $0 \u0026lt; e \u0026lt; 1$：\n$$ e_{i+1} = e_{i+1} - 1, e_{i+1} \u0026gt; 1 $$\n最后，得出这个点的 y：\n$$ y_{i+1} = \\begin{cases} y_i+1 \u0026amp;\\text{if } e_{i+1} \\gt 0.5\\cr y_i \u0026amp;\\text{if } e_{i+1} \\le 0.5\\cr \\end{cases} $$\n上面的算法是 Bresenham's Line 的基本思想，还需要进一步优化，减少浮点数运算。\n可能产生浮点数的地方是 $k = \\frac{\\Delta y}{\\Delta x}$ 和 $e_{i+1} \\gt 0.5$，所以我们最后再把上面所有的过程乘以 $2\\Delta x$。\n最终，我们的代码如下，其中 $\\Delta x = x_2 - x_1, \\Delta y = y_2 - y_1$：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void bresenham(int x1, int y1, int x2, int y2) { int m = 2 * (y2 - y1); int slope_error = m - (x2 - x1); for (int x = x1, y = y1; x \u0026lt;= x2; x++) { putpixel(x, y, RED); slope_error += m; if (slope_error \u0026gt;= 0) { y++; slope_error -= 2 * (x2 - x1); } } } 最后的代码虽然看起来简洁，但是因为优化过，第一次接触容易摸不着头脑。\n其他算法 还有一种叫 Mid-Point Line ，因为它即没有 DDA 简单直接，也没有 Bresenham 效率高，这里就不介绍了。\n","date":"2023-12-08T23:12:03+08:00","permalink":"https://nonlinearthink.github.io/p/%E7%BC%96%E5%86%99%E5%85%89%E6%A0%85%E5%8C%96%E6%B8%B2%E6%9F%93%E5%99%A8%E4%B8%89%E7%BB%98%E5%88%B6%E7%9B%B4%E7%BA%BF/","title":"编写光栅化渲染器（三）绘制直线"},{"content":"我们的第一个目标就是创建一个窗口，创建窗口有很多库都能做，如果你不想要用任何第三方库也不需要跨平台，用 Win32 API 就可以做，不过微软的匈牙利命名法实在是抽象，要有心里准备。\nSDL 库简介 SDL (Simple DirectMedia Layer) 是一个开源、跨平台、轻量级的多媒体层，作者目前在 Valve 任职，也就是大家最喜欢的 Steam，我们基本上只需要用到 SDL_Window 和 SDL_Surface 就可以。\n这里默认大家拥有 C++ 和 CMake 基础，不介绍怎么安装这个库了，直接开始。\n创建 Window 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #define SDL_MAIN_HANDLED #include \u0026#34;SDL.h\u0026#34; int main(int argc, char* argv[]) { // 定义窗口大小 const int width = 640; const int height = 480; // SDL 初始化 if (SDL_Init(SDL_INIT_EVENTS) \u0026lt; 0) { SDL_Log(\u0026#34;SDL init failed\u0026#34;); return 1; } // 创建 SDL 窗口 SDL_Window* window = SDL_CreateWindow( \u0026#34;SoftRenderer\u0026#34;, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, wWidth, wHeight, SDL_WINDOW_SHOWN); if (!window) { SDL_Log(\u0026#34;create window failed\u0026#34;); SDL_Quit(); return 1; } // 一直循环，直到触发了 SDL_QUIT 事件（窗口被关闭） bool isQuit = false; SDL_Event event; while (!isQuit) { while (SDL_PollEvent(\u0026amp;event)) { if (event.type == SDL_QUIT) { isQuit = true; } } } // 释放资源 SDL_DestroyWindow(window); SDL_Quit(); return 0; } 这是一个最简单的 SDL 创建窗口的程序。\nSDL CPU 渲染：获取和更改 Surface 从 Window 可以获取一个 Surface，它和 Window 的大小相同高，并且它里面有一个 pixels 指针，可以访问每一个像素的数据。\n1 2 3 4 5 6 7 8 9 10 while (!isQuit) { ... // 获取窗口的 Surface SDL_Surface* surface = SDL_GetWindowSurface(window); // 像素数据在 surface-\u0026gt;pixels 中 // 更改 Surface 颜色 SDL_FillRect(surface, NULL, SDL_MapRGB(surface-\u0026gt;format, 0, 255, 0)); // 更新窗口的 Surface SDL_UpdateWindowSurface(window); } 从 Window 获取的 Surface 的格式可能并不是我们想要的。\n默认的 Window Surface 每一个像素是 32 位，但是实际上用的只有 24 位，我们就需要给每个像素写入这样：\n1 0x00FF0000 // RGB 红色 因为计算机中存储非 2 的幂次大小的数据会有性能问题，所以 SDL 这里数据是 32 位的，实际使用却是 24 位，头两位是无意义的。\n我们可能更希望使用 RGBA 格式的数据，RGBA 刚好就是 32 位：\n1 0xFF0000FF // RGBA 红色 这个时候我建议自己额外建一个 Surface，渲染完之后再更新给 Window 的 Surface。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 while (!isQuit) { ... // 创建 RGBA 的 render surface SDL_Surface* render_surface = SDL_CreateRGBSurfaceWithFormat( 0, width, height, 32, SDL_PIXELFORMAT_RGBA8888); // 渲染 render surface SDL_FillRect(render_surface, NULL, SDL_MapRGBA(surface-\u0026gt;format, 0, 255, 0, 255)); // 获取 window surface SDL_Surface* window_surface = SDL_GetWindowSurface(window); // 更新 render surface 到 window surface SDL_BlitSurface(render_surface, NULL, window_surface, NULL); // 更新 window surface 到 screen SDL_UpdateWindowSurface(window); // 释放 render surface SDL_FreeSurface(render_surface); } SDL GPU 渲染：Renderer 和 Texture 这一小节为补充内容，如果目标是做 CPU 的软渲染器，不需要了解。\n在 SDL 中，有两种方法可以去做渲染图形，一种是通过 SDL_Surface，另外一种是通过 SDL_Texture。\n区别在于 SDL_Surface 是在 CPU 中，而 SDL_Texture 在 GPU 中。\n使用 GPU 渲染必须要先创建 Renderer：\n1 2 3 4 5 6 SDL_Renderer* renderer = SDL_CreateRenderer(window, -1, 0); if (!renderer) { SDL_Log(\u0026#34;create renderer failed.\u0026#34;); SDL_Quit(); return 1; } 还需要创建一张 Texture，我们不会直接绘制 Renderer，而是绘制在 Texture 上，在计算机图形学中，这种图像绘制在纹理上而不是屏幕上的技术叫做 Render Target Texture。\n1 2 3 4 5 6 7 SDL_Texture* rtt = SDL_CreateTexture(app-\u0026gt;_renderer, SDL_PIXELFORMAT_RGBA8888, 0, width, height); if (!rtt) { SDL_Log(\u0026#34;create renderer target texture failed.\u0026#34;); SDL_Quit(); return 1; } 每帧调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 while (!isQuit) { ... // 设置默认背景颜色 SDL_SetRenderDrawColor(renderer, 0, 0, 0, 255); // 清空屏幕 SDL_RenderClear(renderer); // 创建一个 Surface 来更改像素 SDL_Surface* surface = SDL_CreateRGBSurfaceWithFormat( 0, width, height, 32, SDL_PIXELFORMAT_RGBA8888); // 渲染，更改像素 SDL_FillRect(surface, NULL, SDL_MapRGBA(surface-\u0026gt;format, 0, 255, 0, 255)); // 更新 Surface 到 Texture 上 SDL_UpdateTexture(rtt, NULL, surface-\u0026gt;pixels, surface-\u0026gt;pitch); SDL_FreeSurface(surface); // 覆盖 Texture 到 Renderer 里面 SDL_RenderCopy(renderer, rtt, NULL, NULL); // 发送数据到 GPU SDL_RenderPresent(renderer); } 改写 C 风格的代码 SDL 是一个 C 的库，而不是 C++，这样风格的代码在 C++ 中是不安全和不便利的。所以我们需要做一些改造。\n使用智能指针 SDL 中有很多成对的比如 SDL_CreateWindow 和 SDL_DestroyWindow 函数。如果我们能自动释放就好了，可以用智能指针来解决这个问题。\n尝试重写智能指针的 Deleter：\n1 2 3 4 struct SDL_Window_Deleter { void operator()(SDL_Window* window) const { SDL_DestroyWindow(window); } }; using Unique_SDL_Window_Ptr = std::unique_ptr\u0026lt;SDL_Window, SDL_Window_Deleter\u0026gt;; 使用起来也格外方便：\n1 2 3 Unique_SDL_Window_Ptr window = Unique_SDL_Window_Ptr(SDL_CreateWindow( \u0026#34;SoftRenderer\u0026#34;, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, width, height, SDL_WINDOW_SHOWN | SDL_WINDOW_RESIZABLE)); 尝试自己实现 SDL_Surface 的 Deleter\n使用 Class 封装 之前的 SDL 代码大致可以分为两个部分，一个是在 while 循环之前的初始化阶段，还有一个是在 while 循环内部的每帧执行阶段。\n1 2 3 4 5 6 7 8 RenderApplication app(width, height); if (!app-\u0026gt;InitApplication()) { return 1; } while (app-\u0026gt;running) { app-\u0026gt;Tick(); } 最终，RenderApplication 长这个样子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 class RenderApplication { public: int width, height; bool running; RenderApplication(int _width, int _height) : width(_width), height(_height), running(true) { renderer_ = std::make_unique\u0026lt;SoftRenderer::Renderer\u0026gt;( width, height, SoftRenderer::Color::Black()); } ~RenderApplication() { // 这里不需要释放，因为 window 会释放它 window_surface_ = nullptr; SDL_Quit(); } bool InitApplication() { if (SDL_Init(SDL_INIT_EVENTS) \u0026lt; 0) { SDL_Log(\u0026#34;SDL init failed\u0026#34;); return false; } window_ = Unique_SDL_Window_Ptr(SDL_CreateWindow( \u0026#34;SoftRenderer\u0026#34;, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, width, height, SDL_WINDOW_SHOWN | SDL_WINDOW_RESIZABLE)); if (!window_) { SDL_Log(\u0026#34;create window failed.\u0026#34;); SDL_Quit(); return false; } window_surface_ = SDL_GetWindowSurface(window_.get()); event_ = std::make_unique\u0026lt;SDL_Event\u0026gt;(); return true; } void Tick() { while (SDL_PollEvent(event_.get())) { if (event_-\u0026gt;type == SDL_QUIT) { running = false; return; } } // 渲染前的准备 Unique_SDL_Surface_Ptr render_surface(SDL_CreateRGBSurfaceWithFormat( 0, width, height, 32, SDL_PIXELFORMAT_RGBA8888)); renderer_-\u0026gt;PrepareRender((Uint32*)render_surface-\u0026gt;pixels); // 清空屏幕 renderer_-\u0026gt;Clear(); // 自定义渲染函数 render(); // 更新 renderer surface 到 window surface SDL_BlitSurface(render_surface.get(), NULL, window_surface_, NULL); // 更新 window surface 到 screen SDL_UpdateWindowSurface(window_.get()); // 保持稳定的帧数 SDL_Delay(1000 / 60); } virtual void render() {} protected: std::unique_ptr\u0026lt;SoftRenderer::Renderer\u0026gt; renderer_; Unique_SDL_Window_Ptr window_; SDL_Surface* window_surface_; std::unique_ptr\u0026lt;SDL_Event\u0026gt; event_; }; ","date":"2023-12-05T12:08:06+08:00","permalink":"https://nonlinearthink.github.io/p/%E7%BC%96%E5%86%99%E5%85%89%E6%A0%85%E5%8C%96%E6%B8%B2%E6%9F%93%E5%99%A8%E4%BA%8Csdl%E5%BA%93%E7%AE%80%E4%BB%8B/","title":"编写光栅化渲染器（二）SDL库简介"},{"content":"光栅化 VS 光线追踪 图形学研究如何使用计算机模拟现实，当我们在谈渲染的时候，大致可以分为两个方向：\nRay Tracing，即光线追踪，一般用于离线渲染，效果好，但是计算量大，耗时长。 Rasterization，即光栅化，一般用于实时渲染，效果差，但是计算量小，耗时短。 实际上，在现代 GPU 和各种光栅化渲染算法的的加持下，光栅化的效果已经非常逼真了，光栅化的效果一点也不差。只是相比于光线追踪来说，效果还是差点。\n一个简单的光线追踪流程：发射一条光线，经过一系列地镜面反射、漫反射、折射等现象，最终打到一个物体上，得到一个颜色。几个原因导致了计算量的爆炸：\n像素数量多 因为反射和折射结果不稳定，一个像素需要几十甚至上百次采样平均才能获得一个稳定的结果 每一次采样都会反射或者折射很多次 每一次反射或者折射，都需要和场景中的每个物体相交判断，不过使用屏幕空间划分技术可以解决这个问题 总结一下，光线追踪的时间复杂度：Pixel * Sampling * (Reflection + Refraction) * (Object + Light)，堪称炸裂。\n如果你使用了屏幕空间划分技术（例如 BVH），会让结果好很多：Pixel * Sampling * (Reflection + Refraction) * log(Object + Light)。\n还有一种优化思路，就是让采样结果更加稳定，一旦采样结果稳定了，就可以大幅减少采样数量，在传统的 Whitted Style Ray Tracing 中，具体的措施有比如通过蒙特卡洛方法求各种表面和光源的概率分布，比如对光源进行重要性采样。\n一个简单的光栅化流程：把场景中所有物体的点经过矩阵计算映射到 2D 屏幕空间，三个顶点构成一个三角形，对每一个像素，取最近的三角形，计算三角形在这个像素的颜色（通过三个顶点颜色插值）。\n像素 无论是哪一种，都需要靠屏幕来展示它们，屏幕由一个一个像素构成，那么什么是像素呢？\n通常来说，大部分普通人眼里的像素是这样的：\n这种网格模型深入人心，但是这种模型仅仅在光栅化的时候才是可接受的，对于光线追踪来说，可能完全不是这样。\n像素并不是你想得那么简单，更加专业的图形学人会告诉你：像素是一组离散的对场景颜色的采样结果，之所以这么说，是因为像素可能是一个采样点，也可能是多个采样点混合而成的，它的采样区域可能是方形的，也可能是圆形的。\n所以，网格像素模型只是一种光栅化的时候简化像素的处理：我们认为在这个网格区域内，只产生一次采样，它处于网格的正中心。\n那么如果要渲染一个场景，只需要把每一个网格填上颜色就可以了，光栅化实际上就是在聊怎么填颜色这件事情。比如你需要对场景里的物体进行排序，离相机近的物体表面颜色就是你想要绘制的图形的颜色。\n光线追踪技术则是基于物理，从一个像素点出发，经过多次反射，得到最终颜色，但是一个像素一条射线远远不够，因为这样误差会很大，往往一个像素需要数百条射线的结果求平均。\n光线追踪的本质就是对场景不断进行采样以降低噪点，最终得到最接近真实的图像。\n从时间复杂度来说，光栅化无疑比光线追踪来得更加好，但是因为缺少严谨的物理模型，光栅化的效果比光线追踪差很多，所以在对性能要求不高，但是对效果要求高的离线渲染中，光线追踪被普遍运用。\n截至文章编写日期，已经有游戏比如 赛博朋克2077 2.0 运用了 Path Tracing 技术，也叫 Monte Calo Ray Tracing，比传统的 Whitted Style Ray Tracing 性能更加好，效果也更棒。\n光栅化程序开发流程 创建一个窗口，并绘制直线，三角形，带有顶点数据的物体。 施工中\u0026hellip;\nReference Fundamentals of Computer Graphics\n","date":"2023-12-02T14:15:23+08:00","permalink":"https://nonlinearthink.github.io/p/%E7%BC%96%E5%86%99%E5%85%89%E6%A0%85%E5%8C%96%E6%B8%B2%E6%9F%93%E5%99%A8%E4%B8%80%E6%A6%82%E8%BF%B0/","title":"编写光栅化渲染器（一）概述"},{"content":"我在大一的时候就在博客园和 CSDN 写博客，主要内容是平时上课学的 C 语言算法和一些简单的入门教程。后来我停止了一段时间，因为我意识到自己在生产毫无价值的垃圾。\n写一篇合格的博客不是一件容易的事情，借本文分享一下自己多年写博客的一些经验。\n前期准备 发掘有价值的话题 什么是有价值的话题？\n一件事的价值本身就因人而异，在技术领域价值的产生是因为有需求，所以一般而言，需求越大，越有价值。但在有一定的需求的情况下，越是困难的工作越有价值，因为困难的工作本身也意味着更少的人能做，在供需关系的影响下，会推高其价值。\n简而言之，需求越大，难度越大，越有价值。\n同时，有一些人可能希望博客拥有一定盈利能力，为自己贡献一部分收入，毕竟自己花了非常多的时间去学习和分享这些资料。\n有意思的是，在技术领域，需求量最大的一般是入门水平的技术博客。因为有非常多的人学习计算机，他们中的大部分甚至将来不会从事相关的工作。大部分时候，做入门水平的内容，不仅轻松而且还赚钱，这种现象造就了 CSDN 这样离谱的网站。\n我知道很多人都鄙视这些大量灌水的入门水平博客，我也不喜欢，但是至少人家是真的懂流量。\n话说回来，我们认为，优秀的博客必然是具有一定原创性的，最好还是具有一定深度的，但是假如你的水平真的有限，那么这两种类型的博客也是可以考虑的：\n总结归纳别人的资料（但是要附上所有的参考链接） 翻译英语社区的内容（要注明为翻译类文章，且附上原文链接） 建立自己的知识库 博客难产的一个重要原因就是肚子里没有墨水，这个不一定是指你不懂这个技术，也可能是你懂这个技术，但是缺乏系统性阐述的资料。\n我们每一个人每天都在不停接收各种非常碎片化的信息，其中的一些可能是鲜为人知的信息，它们可能是具有一定价值的，但是又不足以形成一篇完整的文章。这个时候最好的策略就是存储它们，当有一天，你需要为你的博客准备素材的时候，就不需要到处回忆和寻找了，只需要从你的个人知识库里面复制粘贴就好了。\n常见的知识库有比如国内的语雀，还有国外的 Notion，相对来说，我个人使用 Notion 更多一些。\n成为持续思考的人 不会自己独立思考的人是写不出博客的，就算写也只能写出千篇一律的文章。编写原创性的博客的关键要点就是把你自己转化为一个能持续思考的人。\n但是，思考到底是什么呢？什么叫持续思考？\n在我看来，思考是一种状态，意味着你大部分生物能量不再用于其他活动，全部为大脑使用。只要你活着，大脑一定是在运转的，所以如果仅仅是保持大脑的运转是不足以被称之为“思考”的。\n每当你看到一个东西，听到一个东西，触碰到一个东西，你能够立马就进入这样的状态，就可以被称之为“持续思考”了。\n思考是一种习惯，是可以培养的。假如你现在还做不到，那么可以尝试去做，并且保持下去，可能有一天你就突然反应过来自己成为了这样的人。\n编写博客 设计合理的排版 这可能是我最想吐槽的一点，因为很多 CSDN 的文章，甚至就是生的文本，完全没有排版可言，有些内容其实还可以的，实在是可惜。\n在我看来，Markdown、LaTex 是每一个程序员的必修课，这世界上没有不写博客的程序员，每一个我曾经的同学，他们都写过博客。\n在必要的时候，也可以使用 Markdown 引擎的 HTML 功能来丰富文章的排版。还有，不要忘记 TOC，主要是针对自建网站的同学，大部分博客管理网站都会自动生成。\n学会编写总结 新手的博客往往都是没有总结的，总结是一个非常好的习惯，不仅仅是在写博客的时候，平时你在和其他人交流工作的时候也可以尝试使用总结，可以更好地传达你需要表达的意思。\n总结往往提醒别人，接下来的事情是重点。这样别人就会用更高的注意力去接收信息。\n有一个误区是，很多人认为总结只是复制粘贴文章中的关键信息，但实际上，总结也可以帮助你在完成最终的博客前对文章脉络做一个梳理，帮助你思考文章的结构是否合理，有时候，总结可能还会促使你回去重新调整文章的结构，以增强文章的可读性。\n标注参考资料 新手的博客往往是没有参考资料的，但是这可能是你人生中非常重要的一课：\n你得要学会尊重别人的成果，这样别人才会尊重你的成果。\n有一个问题，是否需要严格按照论文的形式写博客？\n对于这个问题，如果你对自己的要求足够高，那么可以尝试严格使用论文格式去编写博客，但是很多博客并不是什么非常正式的内容，就像这篇文章，可能只是我临时起意，写下来的一些想法。所以我的主张是，你能真实地标注出你所引用的资料，就已经赢过大部分的人了。\n发布博客 博客框架和主题并不重要 我在学生时代玩过不少的博客框架和主题，每一次升级那些主题的新版本，总是要花费我大量的时间去校对配置项，正是因为有了太多边边角角的东西，导致我忘记了最根本的事情：自己是来写博客的。\n有时候，你可能还会使用一些特有的 Markdown 语法，这真的很糟糕，因为当你要去迁移到别的框架或者主题的时候，你就要回去检查以前博客的内容。在搭建技术博客的时候，要规避使用主题特有的一些功能。因为你不知道自己未来会使用怎么样的框架和主题。\n但是，这并不代表我们不需要挑选博客框架和主题。\n我使用 Hugo 框架是因为我喜欢它有优秀的性能，可以非常快速渲染大量博客。\n我使用 Stack 主题是因为它提供了开箱即用的模板，并且高度自动化。\nHugo Theme Stack Starter Template\n不要泄露自己的隐私 在一些博客框架和主题里面，可能需要配置一些密钥等敏感信息，才能使用，比如一些评论系统。有些人会直接把这个信息提交到公共仓库里面，这样有安全风险。\n我的建议是把博客存储仓库和部署仓库分离，并且分离之后把存储仓库设置为私密，不过部署仓库必须设置为公开，这样才可以挂载到 Github Pages 上。\n假如你使用了 Github Actions 来自动化部署，那么可能还需要权限才能向私有仓库提交代码。\n参考 Github 官方文档：Using secrets in GitHub Actions\n先在自己的部署仓库里面创建一个 DEPLOY_KEY，记得勾选写入权限。\n然后在自己的存储仓库里面创建一个 secrets，其值就是上面的 DEPLOY_KEY 的值：\n然后，就可以在 Github Actions 部署的时候加上一个 DEPLOY_KEY：\n1 2 3 4 5 6 7 8 9 10 ... - name: Deploy 🚀 uses: JamesIves/github-pages-deploy-action@v4 with: repository-name: nonlinearthink/nonlinearthink.github.io branch: master ssh-key: ${{ secrets.DEPLOY_KEY }} folder: public clean: true single-commit: true 总结 祝大家都可以编写出优秀的博客！\n","date":"2023-11-22T00:53:17+08:00","permalink":"https://nonlinearthink.github.io/p/%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E4%B8%80%E7%AF%87%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/","title":"如何编写一篇技术博客"},{"content":"我最近想要做一些 C++ 的项目，在正式开始之前，我需要先搭建环境，也是大概花了一个晚上，简单了解了一下现在 C++ 项目都是怎么构建的。\n目前比较主流的两种包管理器：conan 和 vcpkg，我都试用了一下，个人感觉 vcpkg 的兼容性更好一些，应该可以帮我避不少坑，所以最终选择了使用 Vcpkg+CMake+VSCode 去构建我的编程环境。\n我参考了 VsCode+Vcpkg+MSVC——C++开发环境配置 这篇文章，但是他有些地方的坑没讲明白，我重新整理和归纳一下。\n准备 C++ 编译器 Windows: Visual C++(目前使用)、MinGW macOS: Clang、GCC CMake Windows: Download | CMake macOS: brew install\u0026hellip; VSCode CMake Tools C/C++ vcpkg 安装 官方中文文档：vcpkg/README_zh_CN.md at master · microsoft/vcpkg · GitHub\n阅读快速开始的部分，按照指令一条条做。\nGit Clone 不下来？ 运用科技手段 导入项目地址到 Gitee Github 镜像下载网站 运行 bootstrap-vcpkg.bat 或者 bootstrap-vcpkg.sh 卡住并且报错？ 运用科技手段 去这个页面下载 vcpkg.exe: Releases · microsoft/vcpkg-tool (github.com)，然后拷贝到 Clone 下来的 Git 根目录 macOS 应该是下载 vcpkg-macos，我没试过\n配置环境变量 这一步网上很多人没讲，环境变量可以让后面路径的配置和维护方便很多。\n配置一个叫 VCPKG_ROOT 的变量，待会要用，地址就是刚才 Clone 的那个 Git 根目录。\n配置完之后检查一下：\n1 2 3 4 # powershell $env:VCPKG_ROOT # bash echo $VCPKG_ROOT 安装依赖 安装一个库：\n1 .\\vcpkg.exe install fmt:x86-windows 安装依赖一般就是 [库名]:[编译目标]。\n这里补充一个重点，一定要选择和自己的编译器一样的编译目标，我一开始用了 Visual C++ 的 64 位编译器，结果后面编译的时候一直出问题，因为 x86-windows 是 32 位的。\n添加依赖到 CMake 切回到 CMake 项目中。\n在 CMakeLists.txt 中加入两条新的命令，find_package 和 target_link_libraries，编辑完之后大概是这个样子的：\n1 2 3 4 5 6 7 8 9 10 project(TestVcpkg VERSION 0.1.0) ...... add_executable(TestVcpkg main.cpp) ...... find_package(fmt CONFIG REQUIRED) target_link_libraries(TestVcpkg PRIVATE fmt::fmt) target_link_libraries 必须在 find_package 和 add_executable 后面。\n测试程序 引入并使用一下 fmt 库试试。\n1 2 3 4 5 6 #include \u0026#34;fmt/format.h\u0026#34; int main(int, char **) { fmt::print(\u0026#34;Hello, world!\\n\u0026#34;); } 编译 创建一个 CMake 项目，不知道怎么创建，可以参考后面的 VSCode 部分。\n构建项目：\n1 2 3 4 # powershell cmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=$env:VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake # bash cmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=$VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake -B 后面跟着的是 CMakeLists.txt 的位置 -S 后面跟着的是编译到那个位置，一般都是项目目录下新建一个 build 目录 最后跟着的是配置 CMAKE_TOOLCHAIN_FILE，需要用到之前配置的环境变量 VCPKG_ROOT。 编译项目：\n1 cmake --build build 运行 找到 build/Debug 下的可执行文件，运行一下就行了。\n清单模式 不使用这个也能用，但是强烈推荐使用\n简单来说，就是依赖配置文件，会在你运行 CMake 的时候自动帮你安装依赖。\n务必要看一下这个：\n使用清单模式入门 | Microsoft Learn\n清单模式 | Microsoft Learn\nVSCode 配置 VSCode 的主要目的是自动化上面的一些命令。\n建立 Cmake 项目 VSCode 打开一个空目录，使用 Ctrl+Shift+P|⌘+⇧+P 打开 Command Palette，找到并运行 CMake: Quick Start。\nvcpkg 加入 CMake 自动化编译流程 VSCode 会在你更新 CMakeLists.txt 的时候帮你自动运行 CMake 命令，为了在运行的时候加入 CMAKE_TOOLCHAIN_FILE 的设置，你需要编辑 settings.json：\n1 2 3 4 5 6 { \u0026#34;cmake.configureSettings\u0026#34;: { \u0026#34;CMAKE_TOOLCHAIN_FILE\u0026#34;: \u0026#34;${env:VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake\u0026#34;, \u0026#34;VCPKG_TARGET_TRIPLET\u0026#34;: \u0026#34;x86-windows\u0026#34; }, } 这样配置完之后相当于在 cmake 执行的时候加入了：\n1 -DCMAKE_TOOLCHAIN_FILE=$env:VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake -DVCPKG_TARGET_TRIPLET=x86-windows 这里用到的 ${env:VCPKG_ROOT} 就是上面提到的环境变量，而编译目标，取决于你使用的编译器。\n可以在 .vscode 文件夹下新建一个 settings.json，这样可以给每个项目自定义使用 x64-windows 还是 x86-windows\n到这一步为止，保存刷新一下 CMakeLists.txt，VSCode 应该没有报错，并且成功帮你编译好了 CMake，如果有问题，去检查一下上面的流程，特别是 vcpkg 官方文档的内容我没怎么提，仔细检查一下。\n识别和跳转 #include 头文件 默认情况下，代码编辑器会有一个报错，#include 找不到 vcpkg 安装的库，但是执行 Debug 或者 Run 任务，都没有任何问题。\n这是因为 VSCode 没有在 vcpkg 的目录中找头文件。\n再次运行 Ctrl+Shift+P|⌘+⇧+P 打开 Command Palette，找到并使用 C/C++: Edit Configurations(JSON)，它会创建一个 .vscode 文件夹，里面有一个 c_cpp_properties.json 文件，编辑其中的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;configurations\u0026#34;: [ { ...... \u0026#34;includePath\u0026#34;: [ \u0026#34;${workspaceFolder}/**\u0026#34;, \u0026#34;${env:VCPKG_ROOT}/installed/x64-windows/include\u0026#34;, \u0026#34;${env:VCPKG_ROOT}/installed/x86-windows/include\u0026#34; ], ...... } ], ...... } 很多教程会在这里写上一个 ${vcpkgRoot}/x64-windows/include，其实这个 ${vcpkgRoot} 就是我们上面配置的 ${env:VCPKG_ROOT} 加上 installed。\n","date":"2023-04-15T02:48:00+08:00","permalink":"https://nonlinearthink.github.io/p/%E4%BD%BF%E7%94%A8-vcpkg-cmake-vscode-%E7%BC%96%E5%86%99%E4%BD%A0%E7%9A%84-c-%E9%A1%B9%E7%9B%AE/","title":"使用 vcpkg+CMake+VSCode 编写你的 C++ 项目"},{"content":"DDNS(Dynamic Domain Name Server)，它的作用是将用户的动态IP绑定到一个域名上去。\n这样就算你的服务器IP发生了变化，用户仍然可以使用你的域名找到你的服务器。\n阿里云提供了一套API，可以让你用编程的方式实现 DDNS，但是需要你的域名是在阿里云上申请的。\n感谢我的室友借用给我测试用的域名。\n一些可能用到的库 1 2 3 pip install aliyun-python-sdk-core pip install aliyun-python-sdk-alidns pip install pyyaml 获取和缓存 IP 地址 先写一个简单的工具类，可以获取当前电脑的 公网IP 地址，有很多提供这类服务的网站，本例程采用www.3322.org/dyndns/getip。\n获取 IP 之后最好再把它缓存在一个文件中。\n之所以需要缓存是因为阿里云更新两条一样的IP时会报错，我们可以提前缓存，然后下次调用更新服务之前借用缓存的内容，判断当前的 IP 是否无变化。\n定义 IPManager 类 定义一个 IPManager 类，可以获取本机的 公网IP 地址，并使用文件进行缓存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from urllib.request import urlopen import logging class IPManager: def __init__(self, file_cache=\u0026#34;.ipbuffer\u0026#34;): self.ip = \u0026#34;\u0026#34; self.file_cache = file_cache def get_current_ip(self): # 获取当前的 IP with urlopen(\u0026#39;http://www.3322.org/dyndns/getip\u0026#39;) as response: self.ip = str(response.read(), encoding=\u0026#39;utf-8\u0026#39;).replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) logging.info(\u0026#34;current ip: \u0026#34; + self.ip) return self.ip def sync_cache(self): # 同步当前的 IP 到缓存 with open(self.file_cache, \u0026#34;w\u0026#34;) as f: f.write(self.ip) logging.info(\u0026#34;sync cache ip: \u0026#34; + self.ip) def get_cache(self): # 获取缓存的内容 with open(self.file_cache, \u0026#34;r\u0026#34;) as f: old_ip = f.read() logging.info(\u0026#34;get cache ip: \u0026#34; + self.ip) return old_ip 程序默认使用 .ipbuffer 文件存储 IP，我觉得我们还需要先创建这个文件，不然运行的时候可能会报错。\n可以使用下面的函数检查和创建一个文件，支持递归创建:\n1 2 3 4 5 6 7 8 9 10 11 12 import os def check_file(filename): # 获取父文件夹 dirname = os.path.dirname(filename) if not os.path.exists(dirname) and dirname != \u0026#34;\u0026#34;: # 递归创建父文件夹 os.makedirs(dirname) # 创建文件 with open(filename, \u0026#34;w\u0026#34;) as f: f.write(\u0026#34;\u0026#34;) IPManager 的简单使用 1 2 3 4 5 6 7 8 9 10 def main(): # 创建一个 IPManager ip_manager = IPManager() # 获取当前的 IP current_ip = ip_manager.get_current_ip() # 如果 IP 已经缓存就返回 if ip_manager.get_cache() == current_ip: return # 更新 IP 缓存 ip_manager.sync_cache() 这个程序可以 获取IP 并且在 IP无缓存 或者 IP更新 的时候更新缓存。\n获取 accessKeyId 和 accessKeySecret 云账号登录RAM控制台。 在左侧导航栏的人员管理菜单下，单击用户。 在用户登录名称/显示名称列表下，单击目标RAM用户名称。 在用户AccessKey区域下，单击创建新的AccessKey。 摘抄自 阿里云文档\n创建连接阿里云的客户端 1 2 3 4 5 6 7 8 from aliyunsdkcore.client import AcsClient profile = { \u0026#34;accessKeyId\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accessKeySecret\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;cn-hangzhou\u0026#34; } client = AcsClient(profile[\u0026#34;accessKeyId\u0026#34;], profile[\u0026#34;accessKeySecret\u0026#34;], profile[\u0026#34;regionId\u0026#34;]) 把上一步的 accessKeyId、accessKeySecret 填进去。\n在 regionId 填写你的区域号，关于 regionId 的说明，可以见 阿里云官方文档。\n我们需要借助 client.do_action_with_exception 这个函数来发送请求到阿里云。\n域名解析记录查询 之所以需要加一步域名解析记录查询是为了校验我们的域名是否已经被其他的 IP 绑定了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from aliyunsdkalidns.request.v20150109.DescribeDomainRecordsRequest import DescribeDomainRecordsRequest import json import logging def describe_domain_records(client, record_type, subdomain): logging.info(\u0026#34;域名解析记录查询\u0026#34;) request = DescribeDomainRecordsRequest() request.set_accept_format(\u0026#39;json\u0026#39;) request.set_Type(record_type) request.set_DomainName(subdomain) response = client.do_action_with_exception(request) response = str(response, encoding=\u0026#39;utf-8\u0026#39;) result = json.loads(response) logging.debug(result) return result client 是上一步创建的客户端。\nrecord_type 比较复杂，简单来说是 DNS域名解析 的解析类型。我们这里使用 A记录 就好了。\n{% note info %}\n常见的 DNS解析类型\nA: 将主机名(或域名)指向一个 IPv4 地址\nAAAA: 将主机名(或域名)指向一个 IPv6 地址\nCNAME: 将域名指向另一个域名\n{% endnote %}\nsubdomain 填你的域名就好了。\n1 2 # 调用举例 describe_domain_records(client, \u0026#34;A\u0026#34;, \u0026#34;tuenity.xyz\u0026#34;) 添加域名解析记录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from aliyunsdkalidns.request.v20150109.AddDomainRecordRequest import AddDomainRecordRequest import logging import json def add_record(client, priority, ttl, record_type, value, rr, domain_name): logging.info(\u0026#34;添加域名解析记录\u0026#34;) request = AddDomainRecordRequest() request.set_accept_format(\u0026#39;json\u0026#39;) request.set_Priority(priority) request.set_TTL(ttl) request.set_Value(value) request.set_Type(record_type) request.set_RR(rr) request.set_DomainName(domain_name) response = client.do_action_with_exception(request) response = str(response, encoding=\u0026#39;utf-8\u0026#39;) result = json.loads(response) logging.debug(result) return result priority 告诉域名解析服务，按照 priority 从小到大的顺序对记录搜索，搜索到匹配的记录后，就停止搜索 priority 值更大的记录，对于拥有相同 priority 的记录将通过 weight 再次选择 。\n虽然阿里云并不提供 weight 的设置接口，但是你要知道它是个什么东西。\n对于拥有相同 priority 的多条记录，weight 给出了选择某条记录的几率，值越大，被选中的概率就越大，合理的取值范围为 0-65535。\nttl( Time to live )，当用户在访问一个域名的时候，并不是每次都需要去解析一遍的，DNS服务器会在用户当地的递归DNS服务器上缓存一次，在 ttl 的时间长度内失效。一般设置 \u0026ldquo;600\u0026rdquo;。\nrecord_type 同上一步。\nvalue 就是你的 IP地址。\nrr，阿里云的 rr 是主机头的意思，一般设置 \u0026ldquo;www\u0026rdquo;。\ndomain_name 就是你的域名。\n更新域名解析记录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from aliyunsdkalidns.request.v20150109.UpdateDomainRecordRequest import UpdateDomainRecordRequest import logging import json def update_record(client, priority, ttl, record_type, value, rr, record_id): logging.info(\u0026#34;更新域名解析记录\u0026#34;) request = UpdateDomainRecordRequest() request.set_accept_format(\u0026#39;json\u0026#39;) request.set_Priority(priority) request.set_TTL(ttl) request.set_Value(value) request.set_Type(record_type) request.set_RR(rr) request.set_RecordId(record_id) response = client.do_action_with_exception(request) response = str(response, encoding=\u0026#39;utf-8\u0026#39;) logging.debug(response) return response 和上一步的函数接口几乎一摸一样，不过多解释了。\n需要注意，不一样的是 record_id。这个需要 describe_domain_records 函数的返回值。\n1 des_result = describe_domain_records(client, \u0026#34;A\u0026#34;, \u0026#34;tuenity.xyz\u0026#34;) 使用 des_result[\u0026quot;TotalCount\u0026quot;] 就可以查处现在有多少条记录绑定在这个域名上了。\n如果没有，我们就需要调用 add_record ，否则就调用 update_record。\nrecord_id 可以通过 des_result[\u0026quot;DomainRecords\u0026quot;][\u0026quot;Record\u0026quot;][0][\u0026quot;RecordId\u0026quot;] 获取。\n改造、封装建议 使用 yaml 来作为配置文件 使用 python 自带的日志 logging 把查询、更新、添加域名解析记录封装成一个类 获取完整的代码 Github 项目地址\n","date":"2020-10-25T12:08:06+08:00","permalink":"https://nonlinearthink.github.io/p/python-%E5%AE%9E%E7%8E%B0%E9%98%BF%E9%87%8C%E4%BA%91-ddns-%E5%8A%A8%E6%80%81%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/","title":"Python 实现阿里云 DDNS 动态域名解析"},{"content":" 这是一个区别于 uni-app 的纯 H5 的打包方案，不支持小程序，当时还在读大二的时候被我用于一个课程大作业，现在开新项目的话用 taro 更合适。\nCordova 安装 使用 npm 安装 cordova 命令行:\n1 npm install -g cordova 创建 Vue 项目:\n1 vue create cordova-test 找了一圈 Vue 的 Cordova 插件，个人觉得最好用的是这个: vue-cli-plugin-cordova-simple。这位老哥写得这么好，都没人帮他宣传。\n1 vue add vue-cli-plugin-cordova-simple 新建 vue.config.js 文件:\n1 2 3 module.exports = { publicPath: \u0026#34;./\u0026#34;, }; 另外，router 不要使用 history 模式，使用 hash 模式。\niOS 环境配置 iOS 环境只能在 Mac 中配置。\n先用 cordova 命令行为项目添加 iOS 打包工具。\n1 cordova add ios 在 App Store 安装 Xcode\n安装 ios-deploy\n使用 npm 安装:\n1 npm install -g ios-deploy 安装 CocoaPods\ngem 是 Ruby 的包管理器，Mac 自带 Ruby，直接用就行了。\n1 sudo gem install cocoapods 检验环境\n1 cordova requirements 如果没有任何报错，就没问题了。\n运行\n1 2 npm run build cordova run ios 报错: xcode-select: error: tool \u0026lsquo;xcodebuild\u0026rsquo; requires Xcode, but active developer directory \u0026lsquo;/Library/Developer/CommandLineTools\u0026rsquo; is a command line tools instance\n由于我一开始在我的 Mac 上安装环境的时候，单独安装了 Xcode 的 CommandlineTools，后面又安装 Xcode，我的机子上有两个 CommandlineTools。 而当前使用的那个 CommandlineTools 是不在 Xcode 下面的那个。\n我们需要更改一下 CommandlineTools 的目录：\n1 xcode-select -switch /Applications/Xcode.app/Contents/Developer/ Android 环境配置 安装 JDK\n一般来说，推荐使用 JDK 1.8。\n安装 Android Studio\n安装 Android SDK\n打开 Android Studio 的 SDK Manager。\n目前最新版的 cordova-android 是 9.0.0，刚刚支持了 Andorid 10( API 29 )，所以我们就安装 Android 10 就好了。\n早期版本的 cordova-android 和 android api 版本的关系可以去官网。\n创建虚拟设备\n打开 AVD Manager，选一下机型和系统镜像就好了，注意前面的安卓版本兼容。\n安装 Gradle\n首先，你需要一个 Gradle 命令行，直接用 brew 吧。( 安装半天 )\n1 brew install gradle 然后，现在你应该已经能通过 cordova requirements 的测试了，但是还没完。\n因为 Android 打包默认使用 gradle wrapper，所以它应该会下载一个版本的 gradle 到你的本地，路径在 ~/.gralde/wrapper/dists/gradle-xx-all/xxxxx/，建议立刻停止进程，然后自己另外下一个相同版本的替换它。\n把下载链接复制到迅雷，可以快速下载 gradle 包。\n运行\n先打开虚拟设备，然后运行:\n1 2 npm run build cordova run android 题外话 history 和 hash 模式 两者使用上的区别是 history模式 需要一个服务器，而 hash模式 不需要。\nhash模式 通过 URL锚点 模拟页面跳转。 history模式 通过 HTML5 history interface 模拟页面跳转，因为单页面应用只打包出了一个单一的入口，所以需要一个服务器把所有请求重定向到 index.html 上。 如果是网页端开发的话，用 history模式 无疑是最好的，如果是移动端或者桌面端的程序，用 hash模式 更方便。\n配置资源文件 找不到资源文件。因为 Vue 在引用资源文件的时候按绝对路径去寻找，可以把他们作为。这个有解决方案。\n新建 vue.config.js 文件:\n1 2 3 module.exports = { publicPath: \u0026#34;./\u0026#34;, }; 如何寻找Vue插件 开启 Vue 项目管理工具:\n1 vue ui 里面分为依赖和插件两部分。\n依赖一般是官方发布的，能保持最新，且 BUG 较少，就是配置起来麻烦。\n插件就是整合依赖的工具，质量参差不齐，但是插件可以做到开箱即用，很方便。只是有些插件的作者不是很上心，占着显眼的名字，质量却不如一些冷门的好。\n祝大家运行成功！\n","date":"2020-10-04T22:08:07+08:00","permalink":"https://nonlinearthink.github.io/p/%E4%BD%BF%E7%94%A8-cordova-%E6%89%93%E5%8C%85-vue-%E7%9A%84%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BA%94%E7%94%A8/","title":"使用 Cordova 打包 Vue 的移动端应用"},{"content":"像素思维 这一小节，我们将介绍 px(Pixel)。\n逻辑像素而不是物理像素 px 从字面上来看是像素的意思，很多新手一上来可能会认为它的物理像素。\n这里必须要澄清，px一般是指逻辑像素，它会根据浏览器、操作系统、硬件设备做适当的缩放。\n但是，通常96px对应了一个物理英寸。\n像素级的完美与响应式布局 最开始，px 被设计出来的时候所奉行的哲学就是提供像素级别的完美。\n早期的网页设计者会在一个固定大小的页面中设计网页，一般是 800px，你的浏览器如果超过来这个尺寸，必须用水平或者上下滚轮来浏览。每一个元素都是以像素为单位，被精确和巧妙地安排在这个页面中。\n随着高清显示屏的出现，人们开始考虑把网页调大到 1024px，甚至是 1280px，\n设备的种类越来越多，尺寸、像素等等都难以兼容。\n响应式布局是一种能根据屏幕的大小动态调整的布局方式，如今大部分网页都是响应式的，你几乎看不到非响应式的网页了，记得我小时候冲浪就经常遇到那种网页大小不兼容的。\n相对字号的大小单位 em 是一个非常有意思的属性。它是一个相对长度单位，相对于当前元素的字号，也就是相对于 font-size 的大小。\n计算方法 例如，假设已定义当前的 font-size 的大小为 16px ，padding 的大小为 1.2em ，则 padding 的实际大小是多少 px?\n1 2 3 4 .default { font-size: 16px; padding: 1.2em; } 这是一道简单的计算题，padding 的实际大小应该是 $16\\times1.2=19.2(px)$。\n字体大小相对于字体的大小 这是一个有趣的问题，既然 em 是相对于字体的大小单位，那么如果 字体font-size 的大小单位也是 em 会发生什么?\n这种情况下，参照对象不再是元素自身，而是父元素。\n1 2 3 \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;subcontainer\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 1 2 3 4 5 6 7 .container { font-size: 16px; } .subcontainer { font-size: 2em; } 假如父元素的 font-size 是 16px，子元素的 font-size 为 2em，则子元素的实际 font-size 应该为 32px。\n如果父元素没有特别说明，则会一直沿着 DOM树 向上，直到找到一个定义的字体大小为止，你始终可以找到一个定义的字体大小，因为浏览器会给根元素设置一个默认的固定的字体大小。\n浏览器默认字号 对每一个网页的根节点，我们一般使用 伪类选择器:root 来表示，也可以使用 html 来表示。\n大多数浏览器都定义了这个根元素的默认 font-size 为 16px。\n1 2 3 :root { font-size: 16px; } 字体缩小问题 关于 font-size 使用 em ，你应当尽量避免使用，这会造成一个问题，这里有一个比较有趣的例子。\n先做一个无序列表出来:\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; Top level \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; Second level \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; Third level \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 设置无序列表的字体为 0.8em，根据计算，无序列表里面的字体大小应该是 12.8px。\n1 2 3 ul { font-size: .8em; } 效果:\n为什么字体越来越小了？\n我们可以想象，根元素的字体大小是 16px，所以第一级无序列表是 12.8px 没问题，但是第二级无序列表的父元素是第一级无序列表，所以它的字体大小变成了 $12.8\\times0.8=10.24(px)$ 。第三极无序列表的字体大小: $10.24\\times0.8=8.192(px)$。\n字体随着层级越来越多，变得越来越失控。\n正式因为如此，我们一般不推荐使用 em 来定义字体大小，如果你一不小心，就可能造成这种悲剧。\n相对根元素字号的大小单位 根元素伪类选择器 伪类选择器:root，在 HTML 中对应的是 html 标签。\n设置默认字号 以前，网页设计者们为了方便计算，很喜欢利用这个伪类选择器这样写:\n1 2 3 :root { font-size: .875em; } 这是因为 $16\\times0.875=10(px)$，通过这种方式把根元素字号定义为 10px 后，接下来，基于根元素的字号计算可以变得简单一些。\n自定义属性 这是 CSS3 非常重要的一个特性，不过大多数人都会忽略，事实上，我们习惯了使用 SASS/Scss、Less 等等CSS预处理器之后，这个特性已经比较鸡肋了。\n1 2 3 4 5 6 7 8 9 :root { --main-font: Helvetica, Arial, sans-serif; --brand-color: #369; } p { font-family: var(--main-font); color: var(--brand-color) } 如果 var() 函数计算出来的是一个非法值，会设置成对应属性的初始值。\nrem-低复杂度的em rem 是 root rm 的缩写，前面已经介绍过 ，rem 是相对于根元素的字号大小，根元素也就是 :root，或者说是 html。\n1 2 3 4 5 6 7 :root { font-size: 16px; } ul { font-size: .8rem; } ul 的 font-size 大小经过计算是 12.8px。\n这个 css 代码可以解决上面我们的字体缩小问题。\n因为 rem 是相对于根元素字体的大小，就不会引起因为父子元素嵌套而造成的递推缩小现象。\n故此，rem 可以被认为是一种低复杂度的 em 。\n相对视图窗口的大小单位 视图窗口指的是浏览器视图的大小，在桌面端的浏览器中，你可以随意拖动鼠标来调节这个窗口的大小。\n主要涉及的元素是 vh 和 vw，很显然，他们分别是 visual hight 和 visual width 的缩写。\n单位 作用 备注 vh 视图窗口高度的$\\frac{1}{100}$ vw 视图窗口宽度的$\\frac{1}{100}$ vmin 视图窗口高度、宽度中较小一方的$\\frac{1}{100}$ 部分浏览器不支持 vmax 视图窗口高度、宽度中较大一方的$\\frac{1}{100}$ 部分浏览器不支持 你可以认为这些是百分比单位，他们的原子单位都是 1%。\n使用 vh 和 vw 定义字号 1 2 3 :root { font-size: 2vw; } 假设这是在一个 1200px 的显示屏上，字体的大小经过计算是 24px。\n而在一个 768px 的显示屏上，计算值是 15px。\n这实在是太棒了，这是动态可调节的字号。\n但是，如果你把浏览器的宽度放到很小，这太糟糕了，有没有可能设置一个最小值和最大值来限制这种现象？\n使用 calc() 函数 1 2 3 :root { font-size: calc(0.5em + 1vw); } 这个设计的巧妙之处在于，当你缩小到一定程度，1vw 的计算值几乎不可见的时候，0.5em 依然可以保证它至少有 8px 的大小，不至于小到看不见。\n响应式布局入门 响应式布局的精髓是对不同屏幕的适配，我们可以通过媒体查询来定义不同屏幕下的差异。\n媒体查询应当规定一些固定的值，作为后面所有元素的参照，后面所有的元素都应该使用相对单位，除了一些线条可以使用 px，其他一律不建议使用。\n这里只简单谈一些博主的经验，具体还要靠你们实践。\n媒体查询 在 CSS 中，也叫 @meida 规则，它可以指定某种屏幕尺寸或者媒体类型下的样式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 :root { font-size: 0.75em; } @media (min-width: 800px) { :root { font-size: 0.875em; } } @media (min-width: 1200px) { :root { font-size: 1em; } } 在宽度小于 800px 屏幕下，根元素 font-size 的计算值是 12px；\n在宽度大于 800px，但是小于 1200px 的屏幕下，根元素 font-size 的计算值是 14px；\n在宽度大于 1200px 屏幕下，根元素 font-size 的计算值是 16px；\n通过媒体查询，做到了不同屏幕的适配。\n使用大小单位的建议 为了防止布局的不可调整，我们有一些一般性的结论，来使用 CSS 提供的各种单位。\n使用 px 定义线 1 2 3 .default { border: 1px soild #999; } 使用 em 定义间距 1 2 3 .default { padding: 1em; } 使用 rem 定义字号 1 2 3 .default { font-size: 1rem; } 使用 vh 和 vw 定义容器 1 2 3 4 .default { height: 50vh; weight: 50vw; } ","date":"2020-07-08T14:49:49+08:00","permalink":"https://nonlinearthink.github.io/p/css-%E5%83%8F%E7%B4%A0%E5%92%8C%E5%8D%95%E4%BD%8D%E8%AE%A1%E7%AE%97/","title":"CSS 像素和单位计算"},{"content":"box-shadow 概述 先从整体来说说 box-shadow 属性 。\nbox-shadow 支持定义多个阴影，他们应该使用逗号分割:\n1 box-shadow: 3px 3px red, -1em 0 0.4em olive; 这里定义了两个阴影，分别是 3px 3px red、-1em 0 0.4em olive。\n其中，每个阴影支持最多6个字段:\ninset\n可选的字段，默认不指定。\n指定inset，阴影向内扩散，否则阴影向外扩散。\noffset-x 和 offset-y\n用来设置阴影偏移量，分为 x方向 和 y方向。声明的时候，x方向 在前，y方向 在后。\n这个定义的顺序是有讲究的，CSS 的偏移采用的是我们平时定义坐标轴的习惯，按照 (x,y) 的顺序，这个规则不仅仅适用于我们今天的主角 box-shadow ，而且基本上和\u0026quot;位移\u0026quot;、\u0026ldquo;偏移\u0026quot;有关的属性都适用。\n如果两者都是0，那么阴影不做偏移，位于元素正后方。\nblur-radius\n一般情况下，阴影是纯色的，没有渐变区域。\n但是如果设置了模糊半径，就会创建一个渐变区域，向周围的颜色过渡。\n渐变半径必须大于0。\nspread-radius\n扩散半径是对原来的纯色阴影的缩放。\n默认取值为0，代表阴影和物体一样大，但因为阴影在物体后面，所以你看不见。当然加上一层模糊半径你就能看到了。\n小于0的时候，阴影会缩小。这种情况下往往你也看不到，需要设置一层很厚的模糊半径，然后慢慢调低扩散半径你才能看出区别。\n大于0的时候，阴影会扩大。\ncolor\n阴影的颜色，这就不用解释了。\nbox-shadow 很简单，但是对于新手来说，在面对模糊半径和扩散半径可能会有点困惑，接下来，我们将结合例子，更加深入探讨这两者的区别。\n准备: 定义一个球 因为方形的不太适合我们的讲解，我们先定义一个圆形的球:\n1 2 3 4 5 6 7 .ball { height: 100px; width: 100px; border-radius: 50% 50%; margin: 50px; display: inline-block; } 外加一些阴影:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 .b1 { box-shadow: 0px 0px 20px #888; } .b2 { box-shadow: 0px 0px 20px 10px #888; } .b3 { box-shadow: 0px 0px 0px 10px #888; } .b4 { box-shadow: 0px 0px 20px -10px #888; } .b5 { box-shadow: inset 0px 0px 20px #888; } .b6 { box-shadow: inset 0px 0px 20px 10px #888; } .b7 { box-shadow: inset 0px 0px 0px 10px #888; } .b8 { box-shadow: inset 0px 0px 20px -10px #888; } 只有模糊半径 我们先定义一个没有扩散半径的球:\n1 2 \u0026lt;!-- box-shadow: 0px 0px 20px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 可以看到，球的周围有一圈阴影，因为我们没有设置扩散半径，所以我们看到的这层阴影应该是全部的模糊半径。\n我们还可以尝试使用一下内阴影:\n1 2 \u0026lt;!-- box-shadow: inset 0px 0px 20px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b5\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 模糊半径+扩散半径(取正) 接下来我们尝试使用在原来的基础上添加一个扩散半径:\n1 2 3 4 \u0026lt;!-- box-shadow: 0px 0px 20px 10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b2\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- box-shadow: inset 0px 0px 20px 10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b6\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 第一感觉应该是阴影增厚了，再仔细看，我们会发现，增厚的部分的阴影都很浓，也就是说，我们增厚的部分是纯色的阴影，而不是经过了模糊的渐变阴影，这就是所谓的扩散半径。\n只有扩散半径 我们可以把模糊半径去掉，看看差别:\n1 2 3 4 \u0026lt;!-- box-shadow: 0px 0px 0px 10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b3\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- box-shadow: inset 0px 0px 0px 10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b7\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 看到了吗？阴影是纯色的，没有渐变。\n总结下来，模糊半径就是渐变阴影半径，而扩散半径就是纯色阴影半径。并且，渐变阴影包在扩散阴影外面。\n模糊半径+扩散半径(取负) 最后再看一个例子，是扩散半径为负数的时候:\n1 2 3 4 \u0026lt;!-- box-shadow: 0px 0px 20px -10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b4\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- box-shadow: inset 0px 0px 20px -10px #888 --\u0026gt; \u0026lt;div class=\u0026#34;ball b8\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 扩散半径为负数，就是把里面的那层纯色的半径减少了，也就是说，我们目前看到的是模糊半径的一小部分。\n大部分卡片UI的设计就是这种，你们可能很熟悉了，也是我个人觉得最好看的阴影。\n","date":"2020-06-28T00:32:28+08:00","permalink":"https://nonlinearthink.github.io/p/css-%E9%98%B4%E5%BD%B1-%E5%81%8F%E7%A7%BB%E6%A8%A1%E7%B3%8A%E5%8D%8A%E5%BE%84%E6%89%A9%E6%95%A3%E5%8D%8A%E5%BE%84/","title":"CSS 阴影: 偏移、模糊半径、扩散半径"},{"content":"JDBC (Java Database Connectivity) ，属于 Java 应用编程中比较基础的一块，虽然你可以直接使用 MyBatis，但是了解一下 JDBC 可以帮你更好地理解 Java 的数据库编程。\n连接数据库 驱动初始化 基于 Class.forName 的初始化 想要开始 JDBC 编程，第一步是需要把 数据库驱动程序 的代码加载进来。\n可以利用 Class.forName 函数，它原本的功能是返回一个 类或者接口的 Class 对象 ，也就是相当于初始化了一个类，一般用它执行这个类的静态代码段。\n1 2 3 4 5 try { Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } 这样，com.mysql.jdbc.Driver 类中的静态代码段就会被执行，进行初始化。\n不过，驱动初始化还有另外一种写法。\n基于 registerDriver 的初始化 我们知道 Class.forName 是执行类的静态代码段，那我们把 com.mysql.jdbc.Driver 里面的静态代码段照着样子抄一遍不也可以实现初始化吗?\n这是 com.mysql.jdbc.Driver 静态代码段的源代码:\n1 2 3 4 5 6 7 static { try { java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(\u0026#34;Can\u0026#39;t register driver!\u0026#34;); } } 这段代码可以完全代替上一小节的代码，我们可以认为 DriverManager.registerDriver(new Driver()) 和 Class.forName 的写法是等效的。\n什么是 数据库驱动程序 ？\nJDK 提供了一个 JDBC 的接口(Interface)。但是，因为是接口，所以还是没有实现的，每个数据库的厂商需要自己实现这个接口，这样用户才能正常调用。\n以 mysql 为例，下载地址: dev.mysql.com/downloads/connector/j\n接口变动\nmysql5 和 mysql6 的驱动程序接口有区别，从 com.mysql.jdbc.Driver 换成了 com.mysql.cj.jdbc.Driver，再往上的版本同 mysql6 。\n建立连接 数据库打开后会在本地开一个端口，运行进程，我们可以通过这个端口的 URL 来访问数据库。\n当然，还需要数据库的用户名和密码。\n1 java.sql.DriverManager.getConnection(url, user, password); JDBC 的 URL 格式: jdbc:[数据库连接名]://localhost:[端口号]/[数据库名]\n数据库连接名 mysql、sqlserver 端口号 3306(mysql)、1433(sqlserver) 数据库名 业务相关的数据库名，自定义 一个 JDBC 连接数据库的例子:\n1 2 3 4 5 6 try { java.sql.Connection conn = java.sql.DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/booklib\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); } catch (SQLException e) { e.printStackTrace(); } JDBC 基础 Statement Statement 可以根据给出的一条 SQL 字符串，然后调用运行。\n借用上一节连接得到的 conn 对象，它有一个 createStatement 函数，可以创建一个 Statement。\n1 2 3 4 5 6 7 try { java.sql.Connection conn = java.sql.DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/booklib\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); java.sql.Statement st = conn.createStatement(); } catch (SQLException e) { e.printStackTrace(); } execute、executeQuery、executeUpdate 创建完 Statement，就要把 SQL 语句交给 Statement 对象去执行了。\nexecuteQuery 一般如果是运行 查询(select) 语句，推荐使用 第一节中获得的conn 对象的 executeQuery 函数，executeQuery只能返回单个结果集，但是应对大部分的查询已经足够。\n添加下面的代码到上面的 try 代码块中。\n1 2 String sql = \u0026#34;select * from BeanBook\u0026#34;; st.executeQuery(sql); executeUpdate 如果你需要运行 insert、update、delete 等等语句，则可以使用 executeUpdate 函数，它不会返回结果集，但是会返回一个整数，代表受到影响的行数，如果是 0，代表了你没有改变任何数据库的内容，即调用失败了。\n使用 executeUpdate :\n1 2 String sql = \u0026#34;delete from BeanBook where price\u0026gt;50\u0026#34;; st.executeUpdate(sql); execute execute 是更加通用和强大的函数，但是它也比较复杂。它的返回值类型有很多。\nexecute 不仅可以做到 executeQuery 能做的事，也能做到 executeUpdate 能做到的事情。而且，它还能返回多个结果集。\n正因为如此，它一般被用在一些执行未知 SQL 字符串的情况下，如果 SQL 语句能够确定，请尽可能不用 execute。\n它的返回值比较复杂，我们一般使用 getResultSet 和 getUpdateCount 获取，而不是直接把 st.execute(sql); 的结果拿来。\n以下两段代码和上面两小节的 demo 的效果是一样的。\n1 2 3 4 5 6 7 8 9 //代码段1 String sql = \u0026#34;select * from BeanBook\u0026#34;; st.execute(sql); st.getResultSet(); //代码段2 String sql = \u0026#34;delete from BeanBook where price\u0026gt;50\u0026#34;; st.execute(sql); st.getUpdateCount(); ResultSet 前面一直没提 ResultSet，ResultSet 就是 executeQuery 的返回值。\n举个例子，使用 ResultSet 遍历 SQL 的结果:\n1 2 3 4 5 String sql = \u0026#34;select * from BeanBook\u0026#34;; java.sql.ResultSet rs = st.executeQuery(sql); while (rs.next()) { System.out.println(rs.getString(1) + \u0026#34;\\t\u0026#34; + rs.getString(2) + \u0026#34;\\t\u0026#34; + rs.getDouble(4)); } ResultSet 通过 next 函数来遍历，next 从一条记录跳转到下一条记录。\ngetString、getDouble 等等函数接受一个数字 n 作为参数，获得当前记录的第 n 个属性的值，并对这个值进行转换。\n比如 getString(1) 获取第一个属性，转换成 String 类型；getDouble(4) 获取第四个属性，转换成 Double 类型。\n下面是一些 get 函数 (不全):\n原始类型相关 getString、getBoolean、getByte、getShort、getInt、getLong、getFloat、getDouble 日期相关 getDate、getTime、getTimestamp PreparedStatement 通过 conn.prepareStatement 可以来创建一个 PrepareStatement 对象 (conn 是一个 java.sql.Connection)。\n但是这个函数必须要给出一个 SQL 语句作为参数。\n这里也可以看出 PrepareStatement 与 Statement 的一个比较大的区别。Statement 可以一直被复用，但是 PrepareStatement 每执行一次 SQL，都要创建新的 PrepareStatement。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //Statement java.sql.Statement st = conn.createStatement(); Int limit = 50; String sql = \u0026#34;delete from BeanBook where price\u0026gt;50\u0026#34;; st.executeUpdate(sql); String sql2 = \u0026#34;select * from BeanBook\u0026#34;; st.executeQuery(sql2); //PrepareStatement String sql = \u0026#34;delete from BeanBook where price\u0026gt;50\u0026#34;; java.sql.PreparedStatement pst = conn.prepareStatement(sql); st.executeUpdate(); String sql2 = \u0026#34;select * from BeanBook\u0026#34;; java.sql.PreparedStatement pst2 = conn.prepareStatement(sql2); st.executeQuery(); PreparedStatement 和 Statement 一样是用来执行 SQL 语句的，但是 Statement 有很多问题。\n字符串拼接问题 假如我们希望可以动态地设置 SQL 语句，比如，动态改变 where 从句的条件，在 Statement 中，我们需要这样写:\n1 2 3 4 java.sql.Statement st = conn.createStatement(); Int limit = 50; String sql = \u0026#34;delete from BeanBook where price\u0026gt;\u0026#34;+limit; st.executeUpdate(sql); PrepareStatement 允许一种可读性非常好的参数设置语法:\n1 2 3 4 String sql = \u0026#34;delete from BeanBook where price\u0026gt;?\u0026#34;; java.sql.PreparedStatement pst = conn.prepareStatement(sql); pst.setInt(1, 50); st.executeUpdate(sql); 这个 ? 语法可不止可读性好，还有一个更重要的是，它支持了 预编译，这在我们接下来提到的性能问题中会被具体讨论。\n还需要提一下的是 setInt 等等的 set 相关的函数，前面已经提过 get 函数了，基本上把 get 改成 set 就行了。\n性能问题 Statement 的想法是对象只需要创建一次，后续只要传入不同的 SQL 就行了。但是在面对重复都比较高的工作的时候，这可能并不是很好。\n比如，我执行了一次 insert into Beanbook(barcode, bookname, pubid, price, state) values(1, 'Java', 3, 56, '在库')，\n现在我稍微变一下，要插入 insert into Beanbook(barcode, bookname, pubid, price, state) values(2, 'C++', 2, 34, '在库')。\n这两条命令几乎一样，但是我却要编译两次!!!\n我们来看看 PrepareStaement，我们完全可以使用 ? 语法，创建一次模版，因为存在预编译机制，当我们第二次插入的时候节省了一次编译的开销。\n也就是说，在可以使用 ? 语法替换的一系列 SQL 操作中，使用 PrepareStatement 将会节省一大笔开销。\nSQL 注入式攻击 SQL 注入式攻击其实很简单，这是完全可以避免的，但是使用 Statement 的时候你要格外小心。\n假设不怀好意的用户对你的数据库请求删除一些合法的东西，比如删除 bookname 等于 'Java' 的书，但是他传给你的字符串做了一些手脚:\n1 2 3 4 5 //用户的数据 String name=\u0026#34;\u0026#39;Java\u0026#39; OR price\u0026gt;0\u0026#34;; //你的代码 String sql = \u0026#34;delete from BeanBook where bookname=\u0026#34;+name; 好了，你完了，因为字符串拼接的时候，后面的 OR price\u0026gt;0 没有被当作是 bookname 的一部分，而是被当成是 SQL 命令的一部分!!! 在这里，你的数据库已经被清空了。\n但是使用 ? 语法你完全不用担心，因为 PrepareStatement 是预编译的，后面只会插入数据，插入的内容不会被当作是 SQL 命令。\nclose 在数据库的最后不能忘记，关闭连接。\n在原先代码的基础上，在最后的 finally 语句块中加入 close() 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public static void main(String[] args) throws SQLException { java.sql.Connection conn = java.sql.DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/booklib\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); try { conn.setAutoCommit(false); String sql = \u0026#34;select * from BeanBook\u0026#34;; java.sql.PreparedStatement pst = conn.prepareStatement(sql); pst.executeQuery(); } catch (SQLException e) { e.printStackTrace(); } finally { if (conn != null) try { conn.close(); } catch (SQLException e) { e.printStackTrace(); } } } JDBC时间类型的处理 从之前的 get 函数中，我们看到了日期相关的 API。\nJDBC 中一共有三种时间类型:\nDate Time Timestamp System.currentTimeMillis() 这个函数可以获得 系统当前的一个时间戳。\n时间戳是 1970年1月1日0点0分 到现在的毫秒数。\n设置Timestamp 数据库里面存的都是 Timestamp，一般建议存取都用 Timestamp。\n设置当前的时间为 Timestamp:\n1 pst.setTimestamp(5, new java.sql.Timestamp(System.currentTimeMillis())); 通过 Date类 来创建 Timestamp:\n1 2 java.utl.Date date = new java.util.Date(); pst.setTimestamp(5, new java.sql.Timestamp(date.getTime())); 事实上，一般这里直接用字符串也能设置，但对于数据库存在性能问题，一般不建议这样做:\n1 pst.setString(5, \u0026#34;2020-06-27 00:00:00\u0026#34;); 取出Timestamp 因为从数据库直接取出的是 Timestamp，需要使用 SimpleDateFormat 来格式化，才能打印出我们可以识别的时间字符串。\n1 2 3 Timestamp timestamp = rs.getTimestamp(5); SimpleDateFormat sdf = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); System.out.println(sdf.format(timestamp)); 事务控制 为什么需要事务 一个事务是一系列用户定义的数据库操作序列(CRUD)。它的目的是把数据库的多个操作合并抽象成一个操作。\n事务的设计哲学: 要么都成功，要么都失败。这就是事务的原子性。\n事务是隔离的，并发执行的事务之间不互相干扰。\n如何实现 事务的实现靠的是回滚机制。\n当你做完一个操作的时候，都有日志文件记录下你修改的数据。如果你接下来的操作出现了问题，那么数据库就能根据日志文件，运行逆操作，回到原来的状态。\nJDBC中的事务编程 可以在最开始使用 setAutoCommit(false) 来关闭自动提交。\n所谓的自动提交就是，mysql 的 JDBC实现 默认是一旦运行了 execute 相关的那三个函数，就会自动运行 commit() 函数，以更新数据库。\n然后在 try 语句的最后使用 commit() 提交。\n最后不要忘记，异常处理，如果发生了异常，就要使用 rollback() 函数回滚，使前面的操作全部无效。\n我们来看一个结合来前面所有知识的例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import java.sql.SQLException; public class Test { static { try { Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } } public static void main(String[] args) throws SQLException { java.sql.Connection conn = java.sql.DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/booklib\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); try { conn.setAutoCommit(false); String sql = \u0026#34;select * from BeanBook\u0026#34;; java.sql.PreparedStatement pst = conn.prepareStatement(sql); java.sql.ResultSet rs = pst.executeQuery(); while (rs.next()) { System.out.println(rs.getString(1) + \u0026#34;\\t\u0026#34; + rs.getString(2) + \u0026#34;\\t\u0026#34; + rs.getDouble(4)); } sql = \u0026#34;delete from BeanBook where price\u0026gt;50\u0026#34;; pst = conn.prepareStatement(sql); conn.commit(); } catch (SQLException e) { e.printStackTrace(); } finally { if (conn != null) try { conn.rollback(); conn.close(); } catch (SQLException e) { e.printStackTrace(); } } } } mysql 中的存储引擎有: InnoDB、MyISAM等等，但是事务控制只有 InnoDB 支持。\n连接池 连接池的概念 之前每次我们使用数据库 CRUD 的时候，我们每次都需要新建一个连接 Connection。\n创建连接和关闭连接的过程也是比较消耗时间的，当线程数量很大的时候，系统就会变得卡顿。\n连接池就是为了解决这个问题。连接池的设计哲学是: 总是借，而不创建。\n我们在一开始先创建一定数量的连接 Connection，然后每次有请求连接的时候，就找空闲的连接分配过去。如果没有空闲，则需要等待。\n实现连接池 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import java.util.ArrayList; import java.util.List; public class ConnectionPool { int size; List\u0026lt;Connection\u0026gt; conns = new ArrayList\u0026lt;Connection\u0026gt;(); public ConnectionPool(int size) { //构造器 this.size = size; init(); } public void init() { //初始化连接池 try { // Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); //mysql5 Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); // mysql6+ for (int i = 0; i \u0026lt; size; i++) { Connection conn = DriverManager .getConnection(\u0026#34;jdbc:mysql://127.0.0.1:3306/booklib\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;); conns.add(conn); } } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } public synchronized Connection getConnection() { //获得一个连接 while (conns.isEmpty()) { try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } Connection conn = conns.remove(0); return conn; } public synchronized void returnConnection(Connection conn) { //返还一个连接 conns.add(conn); this.notifyAll(); } } 使用开源连接池(以 C3P0 为例) 一些著名的开源连接池\nDBCP C3P0 C3P0连接池 的使用:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.beans.PropertyVetoException; import java.sql.Connection; import java.sql.SQLException; import com.mchange.v2.c3p0.ComboPooledDataSource; public class ConnectionPoo { private static final String url=\u0026#34;jdbc:mysql://localhost:3306/booklib\u0026#34;; private static final String user=\u0026#34;root\u0026#34;; private static final String password=\u0026#34;123456\u0026#34;; private static ComboPooledDataSource dataSource; static{ try { dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(password); dataSource.setJdbcUrl(url); //dataSource.setDriverClass(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); dataSource.setDriverClass(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setInitialPoolSize(5); dataSource.setMinPoolSize(1); dataSource.setMaxPoolSize(10); dataSource.setMaxStatements(50); dataSource.setMaxIdleTime(60); } catch (PropertyVetoException e) { throw new RuntimeException(e); } } public static Connection getConnection() throws SQLException{ return dataSource.getConnection(); } } c3p0 v0.9.2版本 之后，从中分离了一个 mchange-commons-java 包，作为使用 c3p0 的辅助包。我们这里调用的就是辅助包。\nOR映射 JavaBean 一个 JavaBean 对象需要满足的条件:\n提供一个默认的无参构造函数。 需要被序列化并且实现 Serializable 接口。 一系列可读写属性。 一系列的 getter 或 setter 方法。 所有对 JavaBean 属性的访问都应当使用 getter 和 setter 方法。\nJavaBean 是一个可复用的组件，把应用的业务逻辑和显示逻辑分离开，降低了开发的复杂程度和维护成本。\nPOJO (Plain Ordinary Java Object) POJO 是纯粹的 JavaBean。\nJavaBean除了满足上面的条件，没有规定你不能定义其他东西，就算你把一些业务的代码加入进来也没关系。\nPOJO 不允许有业务方法，也不能携带 Connection 之类的方法。\n一个简单的 POJO 对象:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class BeanPublisher { private String pubid; private String publisherName; private String address; public String getPubid() { return pubid; } public void setPubid(String pubid) { this.pubid = pubid; } public String getPublisherName() { return publisherName; } public void setPublisherName(String publisherName) { this.publisherName = publisherName; } public String getAddress() { return address; } public void setAddress(String address) { this.address = address; } } EntityBean 与 OR映射 OR映射 是把数据库对象和编程语言中的对象映射在一起，他们拥有一样的属性。\nEntityBean 一般用于ORM对象关系映射，一个实体映射成一张表。\n它能执行很多自动化操作:\n创建一个 EntityBean 对象相当于创建一条记录 删除一个 EntityBean 对象会同时从数据库中删除对应记录 修改一个 EntityBean 时，容器会自动将 EntityBean 的状态和数据库同步 一些流行的 ORM 框架:\nHibernate MyBatis ","date":"2020-06-28T00:32:28+08:00","permalink":"https://nonlinearthink.github.io/p/jdbc-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E7%A8%8B/","title":"JDBC 数据库编程"},{"content":"因为几个月前买了一台 iPad，而我发现 iPad 最大的问题就是无法编程，所以打算自己搭建一个 jupyter notebook 的远程服务器，云服务器使用的是阿里云。\n我使用的是 Ubuntu 18.04 的镜像，对于其他 linux 服务器，可能也就是包管理器不一样而已。\n远程连接 root 账户。\n无论是本地使用 SSH 还是去阿里云的网站都可，无所谓。\n安装 pip3。\n1 apt install python3-pip 经测试，阿里云的 Ubuntu 18.04 自带 python3，但不带 pip3。\n安装 jupyter 和一些其他想要使用的库。\n1 2 3 pip3 install jupyter pip3 install matplotlib pip3 install sklearn 创建一个文件夹专门来放置 jupyter 的工作目录。\n1 2 3 4 5 6 cd /var/local mkdir jupyter cd jupyter mkdir home cd /var/log touch jupyter.log 生成 jupyter 配置和生成密码的 SHA 值。\n1 2 3 4 jupyter notebook --generate-config ipython \u0026gt; from notebook.auth import passwd \u0026gt; passwd() 注意复制下来，待会要用。\n使用 vim 修改 jupyter_notebook_config.py。\n1 vim ~/.jupyter/jupyter_notebook_config.py 在最后插入以下信息。\n1 2 3 4 5 6 c.NotebookApp.ip = \u0026#39;*\u0026#39; c.NotebookApp.allow_root = True c.NotebookApp.open_browser = False c.NotebookApp.port = 8888 c.NotebookApp.password = u\u0026#39;上面生成的sha值\u0026#39; c.ContentsManager.root_dir = \u0026#39;/var/local/jupyter/home\u0026#39; 安装 nbextensions\n原生 jupyter 的很多体验不是很好，推荐使用一个 jupyter 插件来弥补。\n1 2 3 pip3 install jupyter_contrib_nbextensions jupyter contrib nbextension install --user --skip-running-check jupyter nbextensions_configurator enable --user 先进入 jupyter 配置一下，勾选 Hinterland，这个是自动补全功能。虽然比较简陋，但是也很不错了。\n你可以看到这个插件还有很多其他的功能，可以自己探索一下。\n后台守护进程开启服务器。\n1 nohup jupyter notebook \u0026gt; /var/local/jupyter/runtime.log 2\u0026gt;\u0026amp;1 \u0026amp; 可能需要权限：\n1 nohup jupyter notebook --allow-root \u0026gt; /var/local/jupyter/runtime.log 2\u0026gt;\u0026amp;1 \u0026amp; 由于阿里云的限制，还需要配置一下安全策略。\n打开云服务器的实例界面，选择 本实例安全组-配置规则，可以看到下面的这个界面，添加一条规则就行了。\n在 Safari 中，打开服务器的 IP+端口号 8888。\n","date":"2020-05-10T12:01:48+08:00","permalink":"https://nonlinearthink.github.io/p/%E6%90%AD%E5%BB%BA-jupyter-notebook-%E4%BA%91%E7%AB%AF%E5%B7%A5%E4%BD%9C%E7%AB%99/","title":"搭建 Jupyter Notebook 云端工作站"},{"content":"环境变量 打印环境变量 环境变量就是程序运行时的一系列静态参数，程序在运行时无法修改。\n想要查看所有环境变量，可以使用这个命令：\n1 env 打印单个环境变量 几个比较常见的环境变量。\n变量名 说明 PATH shell将会去这里搜寻命令和程序 SHELL 当前使用的shell类型 HOME 当前用户的根目录 LOGNAME 当前用户的登录名 1 2 3 4 echo $PATH echo $SHELL echo $HOME echo $LOGNAME 定义环境变量 这是 Go 语言的一个环境变量配置。~/.bashrc 中添加下面几行。\n1 export GOROOT=/usr/local/Cellar/go/1.13.5/bin 保存退出后，就可以使用 echo $GOROOT 打印出来了。\n在一个目录下创建 .env 文件，并写入：\n1 GOROOT /usr/local/Cellar/go/1.13.5/bin 可以让这个环境变量仅对在当前目录下运行的应用程序生效。\n更改环境变量的值 有一个比较特殊的环境变量 $PATH，它是环境变量的一个路径集合，既然是集合就可以被不断添加。\n$PATH 以 : 分割，以 path/to/first:path/to/second 这样的形式存在。\n1 export PATH=$PATH:$GOROOT/bin 上面的命令相当于执行了一个 += 操作。也就是在原先的 $PATH 的基础上加上了 $GOROOT/bin。\nShell 配置文件 多用户配置 在 unix-like 系统中，系统配置文件都被放在一个叫 /etc 的目录下。其中也包含了 shell 配置文件。\nshell 配置文件可以分为两类: *profile 和 *shrc。\n*profile 中的内容会在用户登录时被运行。\n*shrc 会在 shell 启动时被运行。\n从生命周期的角度讲，写在 *profile 中的环境变量的生命周期是整个系统运行期间，而 *shrc 仅仅在 shell 被启动的时候才有效。\n生命周期长不一定好，因为我们可能不希望操作系统做太多的初始化而导致开机变慢，所以大部分我们用户自定义的环境变量都是在 *shrc 中。\n但是有些软件，需要他们一开机就运行，比如输入法，就需要写在 *profile 中。\n1 2 3 4 5 6 7 cd /etc ls *profile # output: # profile zprofile ls *shrc # output: # bashrc csh.cshrc zshrc 因为我安装了 zsh，所以多了 zprofile 和 zshrc，没安装过其他的 shell，只有默认的 bash 的话，应该只有 profile 和 bashrc。\n除此之外，忘记说了一点，/etc 文件夹下的配置是针对全部操作系统的用户的，所以请谨慎修改。\n单用户配置 上面说了多用户的环境变量配置，单用户的配置应该使用.bashrc 和 .bash_profile，它们在用户的根目录(~)下，默认是不创建的，如果需要则自己创建。\n1 2 3 4 5 6 7 cd ~ ls .*profile # output: # .bash_profile ls .*shrc # output: # .zshrc 我这里给 bash 创建了 profile，而给 zsh 创建了 shrc，其他没创建。\n值得注意的是，.bash_profile 在默认状态下，还会执行 .bashrc。\n环境变量的优先级 如果在 etc/profile 中和 ~/.bash_profile 都定义了相同的名字的环境变量，会发生什么？\n这个问题，我们可以从配置文件被加载的顺序来考虑。\n以 bash 为例。\n操作系统启动的时候，/etc/profile 被调用，然后 /etc/profile 调用 /etc/bashrc。 用户启动 shell 的时候，~/.bash_profile 被调用，然后 ~/.bash_profile 调用 ~/.bashrc。 最后被调用的会覆盖前面被调用的。\n补充 export 命令 export 命令就是设置环境变量。分两个场景来看：\n在命令行下\n在命令行下的 export 的作用域只有在这次登录期间。\n也就是说 shell 一旦退出，设置的环境变量就消失了。\n如果想要它一直存在，就要写到配置文件中。\n在配置文件中\n如果仔细看过上面的分析，就会知道配置文件是在 shell 登录时候自动加载的。\n自然就不会消失了。\nsource 命令 配置文件写入之后，环境变量不会马上更新。\nsource 命令可以加载一次配置文件的内容。\n比如，配置完上面的内容，使用 source：\n1 source .zshrc alias 命令 alias 就是别名，也就是为命令创建一个别名。\n比如，在 linux 中，python 往往默认是 python2。\n使用 alias 可以设置成 python3。\n1 alias python=python3 alias 也可以当成 export 用。\n区别在于，export 可以直接导入一个文件夹下面的全部可执行文件。\n而 alias 只能针对一个可执行文件，需要你一个一个写。\n1 alias mysql=/usr/local/mysql/bin/mysql 这样之后，我们每次用 mysql 的命令，就会被替换成 /usr/local/mysql/bin/mysql。\nalias 略微简洁明了一点，但其实优势并不是很大，一般都推荐用 export。\n","date":"2019-06-24T02:14:27+08:00","permalink":"https://nonlinearthink.github.io/p/linux-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"Linux 环境变量的那些事"},{"content":"之前一直玩 ubuntu，今天体验了一把 manjaro KDE，界面相当舒适。\n但是，不像 ubuntu gnome 那样自带中文输入法，需要自己安装输入法。\n以 ibus输入法 为例，分享一下如何安装中文输入法。\n安装ibus 安装ibus软件包 1 $ sudo pacman -S ibus 查看所有可用的输入法 1 $ sudo pacman -Ss ^ibus-* 选择一个可用的输入法引擎并安装 1 $ sudo pacman -S ibus-pinyin 运行ibus 1 $ ibus-setup 发现出现提示：\n在 $HOME/.bashrc 中加入下面这段就好了\n1 2 3 export GTK_IM_MODULE=ibus export XMODIFIERS=@im=ibus export QT_IM_MODULE=ibus 添加中文输入法 上一步执行完成之后，就会出现这个界面，到这里添加中文输入法。\n安装过程中的其他问题 这个时候，突然发现每次开机都要在命令行中输入 ibus-setup 才能启动ibus。\n这样很麻烦，为了解决这个问题，原来我们把 $HOME/.bashrc 的内容：\n1 2 3 export GTK_IM_MODULE=ibus export XMODIFIERS=@im=ibus export QT_IM_MODULE=ibus 转移到 $HOME/.xprofile 中，并且在最后一行添加一条新的内容：\n1 2 3 4 export GTK_IM_MODULE=ibus export XMODIFIERS=@im=ibus export QT_IM_MODULE=ibus ibus-daemon -x -d 再重启发现输入法能开机自动启动了。\n","date":"2019-01-15T14:49:48+08:00","permalink":"https://nonlinearthink.github.io/p/manjaro-kde-%E5%AE%89%E8%A3%85-ibus-%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95/","title":"Manjaro KDE 安装 ibus 中文输入法"}]