<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Stall on nonlinearthink</title><link>https://nonlinearthink.github.io/tags/stall/</link><description>Recent content in Stall on nonlinearthink</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 06 Mar 2024 12:23:24 +0800</lastBuildDate><atom:link href="https://nonlinearthink.github.io/tags/stall/index.xml" rel="self" type="application/rss+xml"/><item><title>PARALLEL COMPUTING 课程笔记（一）</title><link>https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/</link><pubDate>Wed, 06 Mar 2024 12:23:24 +0800</pubDate><guid>https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/</guid><description>&lt;p>课程的链接：&lt;a class="link" href="https://gfxcourses.stanford.edu/cs149/fall23" target="_blank" rel="noopener"
>PARALLEL COMPUTING(Standford CS149)&lt;/a>&lt;/p>
&lt;p>本文是我个人的学习笔记，适合没那么多时间想要快速过一遍或者英文不好的同学阅读。&lt;/p>
&lt;h2 id="why-parallelism-why-efficiency">Why Parallelism? Why Efficiency?
&lt;/h2>&lt;h3 id="为什么需要并行">为什么需要并行？
&lt;/h3>&lt;p>在过去很长一段时间，处理器性能的提升得益于两方面：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>指令级并行（Instruction Level Parallelism）的发展&lt;/p>
&lt;p>处理器底层实际上有并行运行的机制，但因为对程序员是不可见的，所以一般人不知道。对于没有依赖关系的指令，现代的处理器会使用并行执行。类似如图所示：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/ILP-Example.png"
width="761"
height="464"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/ILP-Example_hu9aec48c03d118b15d18658d4974aa80e_45814_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/ILP-Example_hu9aec48c03d118b15d18658d4974aa80e_45814_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Instruction Level Parallelism"
class="gallery-image"
data-flex-grow="164"
data-flex-basis="393px"
>&lt;/p>
&lt;blockquote>
&lt;p>“没有依赖关系”是指，这条指令不需要等待其他指令执行完毕，才能执行。&lt;/p>
&lt;/blockquote>
&lt;p>超标量处理器（Superscalar Processor）是指能找到可并行执行的指令，并行运行的处理器，其与普通处理器的区别如图所示：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Simple-Processor.png"
width="172"
height="225"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Simple-Processor_hua11f16dc4db978e1a333e29b0fa29c56_5880_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Simple-Processor_hua11f16dc4db978e1a333e29b0fa29c56_5880_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Simple Processor"
class="gallery-image"
data-flex-grow="76"
data-flex-basis="183px"
>
&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Superscalar-Processor.png"
width="260"
height="226"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Superscalar-Processor_hubda5b55b6ae455fa4940e6c8ff0a20ef_7889_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Superscalar-Processor_hubda5b55b6ae455fa4940e6c8ff0a20ef_7889_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Superscalar Processor"
class="gallery-image"
data-flex-grow="115"
data-flex-basis="276px"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>处理器频率的提升&lt;/p>
&lt;p>著名的摩尔定律：处理器的性能每 18 个月就会翻一番。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>得益于这些原因，在过去很长一段时间内，软件开发者不需要修改任何程序，仅仅更换硬件就能让程序越来越快。&lt;/p>
&lt;p>不幸的是 ILP 的研究已经到顶，CPU 的频率由于要考虑功耗无法再继续提升，如今，处理器的性能提升主要来自于在单位面积中堆叠更多的晶体管：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Processor-Bottleneck.png"
width="658"
height="448"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Processor-Bottleneck_huba270ea9e92bc200c0fd65852bb0fd45_118733_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Processor-Bottleneck_huba270ea9e92bc200c0fd65852bb0fd45_118733_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Processor Bottleneck"
class="gallery-image"
data-flex-grow="146"
data-flex-basis="352px"
>&lt;/p>
&lt;p>与此同时，多核处理器如今已经成为了主流，程序员必须要编写并行的程序才能利用多核处理器的优势。No more free lunch for software developers!&lt;/p>
&lt;h3 id="为什么需要高效">为什么需要高效？
&lt;/h3>&lt;p>仅仅编写并行的程序是不行的，程序也必须是高效的。高效也是讨论并行编程的关键主题。&lt;/p>
&lt;p>而高效的并行编程往往来自于高效的数据访问。&lt;/p>
&lt;h4 id="延迟和停顿">延迟和停顿
&lt;/h4>&lt;p>使用 &lt;code>R0 &amp;lt;- mem[R2]&lt;/code> 指令访问数据，它发起一个请求，把内存中地址 R2 位置的数据传送给 R0 寄存器。在这个过程中，因为需要等待数据传输完毕，会造成一个&lt;code>延迟（Memory Access Latency）&lt;/code>:&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Memory-Access-Latency.png"
width="891"
height="217"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Memory-Access-Latency_hu5e66e14cccb08da32a344cdcf3fd83b4_34747_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Memory-Access-Latency_hu5e66e14cccb08da32a344cdcf3fd83b4_34747_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Memory Access Latency"
class="gallery-image"
data-flex-grow="410"
data-flex-basis="985px"
>&lt;/p>
&lt;p>处理器无法运行下一条指令，因为需要等待上一条指令完成。这种现象叫做 &lt;code>停顿(Stall)&lt;/code>。&lt;/p>
&lt;h4 id="带宽">带宽
&lt;/h4>&lt;p>时钟（Clock） 是指处理器执行一次运算需要的时间。如图所示：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Instruction-Per-Clock.png"
width="605"
height="320"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Instruction-Per-Clock_hu37ef6c801c6583a5d9cf4362cab99d6e_44169_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Instruction-Per-Clock_hu37ef6c801c6583a5d9cf4362cab99d6e_44169_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Instruction Per Clock"
class="gallery-image"
data-flex-grow="189"
data-flex-basis="453px"
>&lt;/p>
&lt;ul>
&lt;li>Math instruction 的运行时长是一次时钟&lt;/li>
&lt;li>Load instruction 的运行时长是不固定的，取决于&lt;code>内存带宽（Memory Bandwidth）&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>如果一些 Math instruction 需要依赖于 Load instruction 的结果，就只能等待，于是就造成一次停顿。&lt;/p>
&lt;p>大部分时候，处理器都在等待数据被加载，内存带宽几乎决定了处理器的运行速度。相比于从内存中加载数据，&lt;strong>The math is &amp;ldquo;free&amp;rdquo;&lt;/strong>.&lt;/p>
&lt;p>所以，高性能的并行程序会尽可能减少从内存中请求数据的次数，并且更倾向于重新计算而不是存储/加载值，这一点可以从 GPU 的 Shader 编程中看出来。&lt;/p>
&lt;h4 id="缓存">缓存
&lt;/h4>&lt;p>使用缓存(Cache)可以减少停顿的长度。什么是缓存？&lt;/p>
&lt;ol>
&lt;li>
&lt;p>缓存是硬件实现，软件程序不需要关注。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>缓存只是管理一份数据的拷贝。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在缓存中读取/写入的速度要比内存快得多。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>缓存以“缓存行(Cache Lines)” 的形式读取/写入数据。&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache.png"
width="185"
height="90"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache_hu4b4c51c3c9b0e9674f1b41b519940502_6041_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache_hu4b4c51c3c9b0e9674f1b41b519940502_6041_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Cache"
class="gallery-image"
data-flex-grow="205"
data-flex-basis="493px"
>&lt;/p>
&lt;p>如图所示，每行由一条指向内存的地址和一定长度的数据组成。每次读取/写入以一行为单位。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>缓存分为很多级别，级别越高，访问速度越快，但容量越小。各个级别的缓存延迟对比图：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache-Latency.png"
width="694"
height="205"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache-Latency_hu8767f4c8e3549bd9e481ce06bed13a5a_24328_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Cache-Latency_hu8767f4c8e3549bd9e481ce06bed13a5a_24328_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Cache Latency"
class="gallery-image"
data-flex-grow="338"
data-flex-basis="812px"
>&lt;/p>
&lt;p>为了尽可能使用速度快的缓存，需要缓存调度策略。比如：Least Recently Used(LRU)。&lt;/p>
&lt;p>在一些现代处理器中，存在预测在未来可能会被访问的数据，并提前放入 Cache 中的逻辑。&lt;/p>
&lt;h3 id="早期的多核处理器">早期的多核处理器
&lt;/h3>&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Multi-Core-Processor.png"
width="622"
height="340"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Multi-Core-Processor_hu05d690df6a319b173859bf07b7841acb_30107_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Multi-Core-Processor_hu05d690df6a319b173859bf07b7841acb_30107_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Multi-Core Processor"
class="gallery-image"
data-flex-grow="182"
data-flex-basis="439px"
>&lt;/p>
&lt;h2 id="a-modern-multi-core-processor">A Modern Multi-Core Processor
&lt;/h2>&lt;h3 id="simd">SIMD
&lt;/h3>&lt;h4 id="什么是-simd">什么是 SIMD
&lt;/h4>&lt;p>SIMD(Single Instruction, Multiple Data) 的核心理念是在多个 ALU 中分摊管理指令流的成本/复杂性，把相同的指令广播给所有的 ALU 并行运行。即一条指令处理多个数据，常用于向量或者矩阵的计算。一个支持 SIMD 的处理器的例子：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Processor.png"
width="173"
height="233"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Processor_hu6f760c5cfe9b47fb3af84e8403cf442b_6941_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Processor_hu6f760c5cfe9b47fb3af84e8403cf442b_6941_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="SIMD Processor"
class="gallery-image"
data-flex-grow="74"
data-flex-basis="178px"
>&lt;/p>
&lt;p>在汇编代码中，有专用的指令：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Instruction.png"
width="154"
height="235"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Instruction_hu71a1251920508e927550de5608b884df_6411_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Instruction_hu71a1251920508e927550de5608b884df_6411_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="SIMD Instruction"
class="gallery-image"
data-flex-grow="65"
data-flex-basis="157px"
>&lt;/p>
&lt;p>这段代码使用一个 256(8 * 32) 位的寄存器存储 8 个数字，并行计算它们并输出结果。&lt;/p>
&lt;blockquote>
&lt;p>SIMD 和 ILP 并不同，SIMD 是使用一条指令计算多个数据，而 ILP 则是基于指令的依赖关系去让一些指令可以并行执行。它们可以同时存在。&lt;/p>
&lt;/blockquote>
&lt;h4 id="simd-的执行分歧">SIMD 的执行分歧
&lt;/h4>&lt;p>如果遇到需要条件执行的程序，使用 SIMD 会导致执行分歧：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Conditional-Execution.png"
width="436"
height="289"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Conditional-Execution_hu13eccc39ddc8d84f37456630df44087a_21413_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/SIMD-Conditional-Execution_hu13eccc39ddc8d84f37456630df44087a_21413_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="SIMD Conditional Execution"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="362px"
>&lt;/p>
&lt;p>这意味着在一段时间内部分 ALU 是不工作的，导致了性能的浪费。在极端的情况下，可能会导致 CPU 仅使用 $\frac{1}{N}$ 的性能（仅有一个 ALU 工作）。&lt;/p>
&lt;h4 id="如何使用-simd">如何使用 SIMD
&lt;/h4>&lt;ul>
&lt;li>Explicit SIMD，程序员使用显式调用封装了 SIMD 的库&lt;/li>
&lt;li>Implicit SIMD，程序员仅编写高级语言的代码，由特殊的编译器自动生成 SIMD 的汇编指令&lt;/li>
&lt;/ul>
&lt;h3 id="线程">线程
&lt;/h3>&lt;p>线程（Thread），是指在一个处理器核心（Core）中，有多个执行上下文，线程并不能真正并行运行，它只是从一个执行上下文切换到另外一个执行上下文，轮流执行。在其他线程执行的时候，执行完的线程也不会结束，会有很长的停顿。&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Threads.png"
width="523"
height="296"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Threads_huca5b485f9c6929f902bba6b48060303e_44609_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Threads_huca5b485f9c6929f902bba6b48060303e_44609_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Threads"
class="gallery-image"
data-flex-grow="176"
data-flex-basis="424px"
>&lt;/p>
&lt;p>使用线程还需要付出代价：因为存储执行上下文的物理单元也是有限的，更多的线程意味着程序的可用执行上下文会更小。&lt;/p>
&lt;h2 id="总结">总结
&lt;/h2>&lt;p>在现代处理器中，实现并行的方法有：&lt;/p>
&lt;ul>
&lt;li>Muti-Core&lt;/li>
&lt;li>ILP&lt;/li>
&lt;li>SIMD&lt;/li>
&lt;li>Thread&lt;/li>
&lt;/ul>
&lt;p>外加实现高效数据读取/写入的 Cache，它们一起构成了这张现代处理器的并行架构图（同时适用于 CPU 和 GPU）：&lt;/p>
&lt;p>&lt;img src="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Parallel-Architectures.png"
width="369"
height="212"
srcset="https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Parallel-Architectures_hua5d7a035de717b3e9cb1022e794ad11a_46897_480x0_resize_box_3.png 480w, https://nonlinearthink.github.io/p/parallel-computing-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/Parallel-Architectures_hua5d7a035de717b3e9cb1022e794ad11a_46897_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Parallel Architectures"
class="gallery-image"
data-flex-grow="174"
data-flex-basis="417px"
>&lt;/p></description></item></channel></rss>